{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: LangGraph Applications ì‹¤ìŠµ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ LangGraphë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = input(\"OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ëŒ€í™”í˜• ì±—ë´‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì±—ë´‡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”!\n",
      "\n",
      "ì‚¬ìš©ì: ì•ˆë…•í•˜ì„¸ìš”!\n",
      "ì±—ë´‡: ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š\n",
      "\n",
      "ì‚¬ìš©ì: ì œ ì´ë¦„ì€ í™ê¸¸ë™ì…ë‹ˆë‹¤.\n",
      "ì±—ë´‡: ë°˜ê°‘ìŠµë‹ˆë‹¤, í™ê¸¸ë™ë‹˜! ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ë³¼ê¹Œìš”? ê¶ê¸ˆí•œ ì ì´ë‚˜ í•„ìš”í•˜ì‹  ì •ë³´ê°€ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ì‚¬ìš©ì: íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°ì— ëŒ€í•´ ì•Œê³  ì‹¶ì–´ìš”.\n",
      "ì±—ë´‡: ì¢‹ì•„ìš”, íŒŒì´ì¬ì€ ë§¤ìš° ì¸ê¸° ìˆëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, ë°°ìš°ê¸° ì‰½ê³  ë‹¤ì–‘í•œ ìš©ë„ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì–´ë–¤ ë¶€ë¶„ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ê¸°ë³¸ ë¬¸ë²•, ë°ì´í„° êµ¬ì¡°, ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ë²•, ì•„ë‹ˆë©´ íŠ¹ì • í”„ë¡œì íŠ¸ì— ëŒ€í•œ ë„ì›€ì„ ì›í•˜ì‹œë‚˜ìš”?\n",
      "\n",
      "ì‚¬ìš©ì: ë¨¸ì‹ ëŸ¬ë‹ë„ ê´€ì‹¬ìˆì–´ìš”.\n",
      "ì±—ë´‡: ë¨¸ì‹ ëŸ¬ë‹ì€ ì •ë§ í¥ë¯¸ë¡œìš´ ë¶„ì•¼ì£ ! íŒŒì´ì¬ì€ ë¨¸ì‹ ëŸ¬ë‹ì„ êµ¬í˜„í•˜ëŠ” ë° ë§¤ìš° ìœ ìš©í•œ ì–¸ì–´ë¡œ, ë‹¤ì–‘í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í”„ë ˆì„ì›Œí¬ê°€ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, **Scikit-learn**ì€ ê¸°ë³¸ì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ê³ , **TensorFlow**ë‚˜ **PyTorch**ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ë° ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "ë¨¸ì‹ ëŸ¬ë‹ì˜ ê¸°ë³¸ ê°œë…ì— ëŒ€í•´ ì„¤ëª…í•´ë“œë¦¬ê±°ë‚˜, íŠ¹ì • ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ì •ë³´ë¥¼ ë“œë¦¬ë©´ ì¢‹ì„ê¹Œìš”?\n",
      "\n",
      "ì‚¬ìš©ì: ì œ ì´ë¦„ì„ ê¸°ì–µí•˜ì‹œë‚˜ìš”?\n",
      "ì±—ë´‡: ë„¤, í™ê¸¸ë™ë‹˜! í•­ìƒ ê¸°ì–µí•˜ê³  ìˆìŠµë‹ˆë‹¤. ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Sequence, Literal\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import operator\n",
    "\n",
    "# í–¥ìƒëœ State ì •ì˜\n",
    "class ChatbotState(MessagesState):\n",
    "    user_info: dict\n",
    "    conversation_style: str\n",
    "    topic_history: list\n",
    "\n",
    "# ë…¸ë“œ í•¨ìˆ˜ë“¤\n",
    "def analyze_intent(state: ChatbotState):\n",
    "    \"\"\"ì‚¬ìš©ì ì˜ë„ ë¶„ì„\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if not messages:\n",
    "        return state\n",
    "    \n",
    "    last_message = messages[-1].content.lower()\n",
    "    \n",
    "    # ê°„ë‹¨í•œ ì˜ë„ ë¶„ì„\n",
    "    if \"ì•ˆë…•\" in last_message or \"hello\" in last_message:\n",
    "        state[\"conversation_style\"] = \"greeting\"\n",
    "    elif \"?\" in last_message:\n",
    "        state[\"conversation_style\"] = \"question\"\n",
    "    elif \"ê°ì‚¬\" in last_message or \"ê³ ë§ˆ\" in last_message:\n",
    "        state[\"conversation_style\"] = \"thanks\"\n",
    "    else:\n",
    "        state[\"conversation_style\"] = \"general\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def extract_entities(state: ChatbotState):\n",
    "    \"\"\"ì—”í‹°í‹° ì¶”ì¶œ\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if not messages:\n",
    "        return state\n",
    "    \n",
    "    last_message = messages[-1].content\n",
    "    \n",
    "    # ì´ë¦„ ì¶”ì¶œ (ê°„ë‹¨í•œ ì˜ˆì œ)\n",
    "    if \"ì œ ì´ë¦„ì€\" in last_message or \"ì €ëŠ”\" in last_message:\n",
    "        import re\n",
    "        pattern = r\"(?:ì œ ì´ë¦„ì€|ì €ëŠ”)\\s+(\\S+)(?:ì…ë‹ˆë‹¤|ì´ì—ìš”|ì˜ˆìš”)?\"\n",
    "        match = re.search(pattern, last_message)\n",
    "        if match:\n",
    "            if \"user_info\" not in state:\n",
    "                state[\"user_info\"] = {}\n",
    "            state[\"user_info\"][\"name\"] = match.group(1)\n",
    "    \n",
    "    # ì£¼ì œ ì¶”ì¶œ\n",
    "    topics = []\n",
    "    keywords = [\"íŒŒì´ì¬\", \"í”„ë¡œê·¸ë˜ë°\", \"AI\", \"ë¨¸ì‹ ëŸ¬ë‹\", \"ì›¹ê°œë°œ\"]\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in last_message.lower():\n",
    "            topics.append(keyword)\n",
    "    \n",
    "    if topics:\n",
    "        if \"topic_history\" not in state:\n",
    "            state[\"topic_history\"] = []\n",
    "        state[\"topic_history\"].extend(topics)\n",
    "    \n",
    "    return state\n",
    "\n",
    "def generate_response(state: ChatbotState):\n",
    "    \"\"\"ì‘ë‹µ ìƒì„±\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    system_content = \"ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "    \n",
    "    # ì‚¬ìš©ì ì •ë³´ ë°˜ì˜\n",
    "    if state.get(\"user_info\", {}).get(\"name\"):\n",
    "        system_content += f\" ì‚¬ìš©ìì˜ ì´ë¦„ì€ {state['user_info']['name']}ì…ë‹ˆë‹¤.\"\n",
    "    \n",
    "    # ëŒ€í™” ìŠ¤íƒ€ì¼ ë°˜ì˜\n",
    "    style_prompts = {\n",
    "        \"greeting\": \" ì¹œê·¼í•˜ê²Œ ì¸ì‚¬í•˜ì„¸ìš”.\",\n",
    "        \"question\": \" ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\",\n",
    "        \"thanks\": \" ê°ì‚¬ ì¸ì‚¬ì— ê²¸ì†í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”.\",\n",
    "        \"general\": \" ëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ì„¸ìš”.\"\n",
    "    }\n",
    "    system_content += style_prompts.get(state.get(\"conversation_style\", \"general\"), \"\")\n",
    "    \n",
    "    # ì£¼ì œ ê¸°ë¡\n",
    "    if state.get(\"topic_history\"):\n",
    "        recent_topics = list(set(state[\"topic_history\"][-5:]))\n",
    "        system_content += f\" ìµœê·¼ ëŒ€í™” ì£¼ì œ: {', '.join(recent_topics)}\"\n",
    "    \n",
    "    messages = [SystemMessage(content=system_content)] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# ê·¸ë˜í”„ êµ¬ì„±\n",
    "def create_chatbot():\n",
    "    workflow = StateGraph(ChatbotState)\n",
    "    \n",
    "    # ë…¸ë“œ ì¶”ê°€\n",
    "    workflow.add_node(\"analyze\", analyze_intent)\n",
    "    workflow.add_node(\"extract\", extract_entities)\n",
    "    workflow.add_node(\"respond\", generate_response)\n",
    "    \n",
    "    # ì—£ì§€ ì¶”ê°€\n",
    "    workflow.set_entry_point(\"analyze\")\n",
    "    workflow.add_edge(\"analyze\", \"extract\")\n",
    "    workflow.add_edge(\"extract\", \"respond\")\n",
    "    workflow.add_edge(\"respond\", END)\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ì™€ í•¨ê»˜ ì»´íŒŒì¼\n",
    "    memory = MemorySaver()\n",
    "    return workflow.compile(checkpointer=memory)\n",
    "\n",
    "# ì±—ë´‡ ì‹¤í–‰\n",
    "chatbot = create_chatbot()\n",
    "config = {\"configurable\": {\"thread_id\": \"session1\"}}\n",
    "\n",
    "print(\"ì±—ë´‡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”!\\n\")\n",
    "\n",
    "# ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜\n",
    "test_messages = [\n",
    "    \"ì•ˆë…•í•˜ì„¸ìš”!\",\n",
    "    \"ì œ ì´ë¦„ì€ í™ê¸¸ë™ì…ë‹ˆë‹¤.\",\n",
    "    \"íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°ì— ëŒ€í•´ ì•Œê³  ì‹¶ì–´ìš”.\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ë„ ê´€ì‹¬ìˆì–´ìš”.\",\n",
    "    \"ì œ ì´ë¦„ì„ ê¸°ì–µí•˜ì‹œë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"ì‚¬ìš©ì: {msg}\")\n",
    "    result = chatbot.invoke(\n",
    "        {\"messages\": [HumanMessage(content=msg)]},\n",
    "        config\n",
    "    )\n",
    "    print(f\"ì±—ë´‡: {result['messages'][-1].content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SQL Query Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì§ˆë¬¸: Engineering ë¶€ì„œì˜ í‰ê·  ê¸‰ì—¬ëŠ”?\n",
      "============================================================\n",
      "SQL: SELECT AVG(salary) AS average_salary\n",
      "FROM employees\n",
      "WHERE department = 'Engineering';\n",
      "\n",
      "ê²°ê³¼:\n",
      "   average_salary\n",
      "0         75000.0\n",
      "\n",
      "ì„¤ëª…: ì‚¬ìš©ìê°€ ìš”ì²­í•œ Engineering ë¶€ì„œì˜ í‰ê·  ê¸‰ì—¬ëŠ” 75,000ë‹¬ëŸ¬ì…ë‹ˆë‹¤. ì¦‰, Engineering ë¶€ì„œì— ê·¼ë¬´í•˜ëŠ” ì§ì›ë“¤ì˜ ê¸‰ì—¬ë¥¼ ëª¨ë‘ í•©ì‚°í•œ í›„, ì§ì› ìˆ˜ë¡œ ë‚˜ëˆˆ ê²°ê³¼ê°€ 75,000ë‹¬ëŸ¬ë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ì´ëŠ” í•´ë‹¹ ë¶€ì„œì˜ ì§ì›ë“¤ì´ í‰ê· ì ìœ¼ë¡œ ì´ ì •ë„ì˜ ê¸‰ì—¬ë¥¼ ë°›ê³  ìˆë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "ì§ˆë¬¸: ê°€ì¥ ë†’ì€ ê¸‰ì—¬ë¥¼ ë°›ëŠ” ì§ì›ì€?\n",
      "============================================================\n",
      "SQL: SELECT * FROM employees WHERE salary = (SELECT MAX(salary) FROM employees);\n",
      "\n",
      "ê²°ê³¼:\n",
      "   id name   department   salary   hire_date\n",
      "0   3  ë°•ë¯¼ìˆ˜  Engineering  80000.0  2018-07-10\n",
      "\n",
      "ì„¤ëª…: ì‚¬ìš©ìê°€ ìš”ì²­í•œ \"ê°€ì¥ ë†’ì€ ê¸‰ì—¬ë¥¼ ë°›ëŠ” ì§ì›\"ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•œ ê²°ê³¼, ë°•ë¯¼ìˆ˜ë¼ëŠ” ì§ì›ì´ ê°€ì¥ ë†’ì€ ê¸‰ì—¬ë¥¼ ë°›ê³  ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ê·¸ì˜ ê¸‰ì—¬ëŠ” 80,000ë‹¬ëŸ¬ì´ë©°, ì†Œì† ë¶€ì„œëŠ” ì—”ì§€ë‹ˆì–´ë§ì…ë‹ˆë‹¤. ë°•ë¯¼ìˆ˜ëŠ” 2018ë…„ 7ì›” 10ì¼ì— íšŒì‚¬ì— ì…ì‚¬í–ˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì¦‰, í˜„ì¬ íšŒì‚¬ì—ì„œ ê°€ì¥ ë†’ì€ ê¸‰ì—¬ë¥¼ ë°›ëŠ” ì§ì›ì€ ë°•ë¯¼ìˆ˜ì´ë©°, ê·¸ì˜ ê¸‰ì—¬ëŠ” 80,000ë‹¬ëŸ¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì§ˆë¬¸: Active ìƒíƒœì¸ í”„ë¡œì íŠ¸ë“¤ì˜ ì´ ì˜ˆì‚°ì€?\n",
      "============================================================\n",
      "SQL: SELECT SUM(budget) AS total_budget\n",
      "FROM projects\n",
      "WHERE status = 'Active';\n",
      "\n",
      "ê²°ê³¼:\n",
      "   total_budget\n",
      "0      200000.0\n",
      "\n",
      "ì„¤ëª…: ì‚¬ìš©ìê°€ ìš”ì²­í•œ \"Active ìƒíƒœì¸ í”„ë¡œì íŠ¸ë“¤ì˜ ì´ ì˜ˆì‚°\"ì— ëŒ€í•œ SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•œ ê²°ê³¼, í˜„ì¬ í™œì„± ìƒíƒœì¸ í”„ë¡œì íŠ¸ë“¤ì˜ ì˜ˆì‚°ì„ ëª¨ë‘ í•©ì‚°í•œ ê²°ê³¼ê°€ 200,000.0ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì¦‰, í˜„ì¬ ì§„í–‰ ì¤‘ì¸ í”„ë¡œì íŠ¸ë“¤ì˜ ì´ ì˜ˆì‚°ì€ 200,000ì…ë‹ˆë‹¤. ì´ëŠ” ëª¨ë“  í™œì„± í”„ë¡œì íŠ¸ì˜ ì˜ˆì‚°ì„ í•©ì¹œ ê¸ˆì•¡ìœ¼ë¡œ, ì´ ê¸ˆì•¡ì´ í•´ë‹¹ í”„ë¡œì íŠ¸ë“¤ì„ ìš´ì˜í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì§ˆë¬¸: ë¶€ì„œë³„ ì§ì› ìˆ˜ëŠ”?\n",
      "============================================================\n",
      "SQL: SELECT department, COUNT(*) AS employee_count\n",
      "FROM employees\n",
      "GROUP BY department;\n",
      "\n",
      "ê²°ê³¼:\n",
      "    department  employee_count\n",
      "0  Engineering               2\n",
      "1           HR               1\n",
      "2    Marketing               2\n",
      "\n",
      "ì„¤ëª…: ìœ„ SQL ì¿¼ë¦¬ì˜ ê²°ê³¼ëŠ” ê° ë¶€ì„œë³„ë¡œ ì§ì› ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì•„ë˜ì™€ ê°™ì´ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "- **Engineering (ì—”ì§€ë‹ˆì–´ë§) ë¶€ì„œ**ì—ëŠ” ì´ **2ëª…**ì˜ ì§ì›ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "- **HR (ì¸ì‚¬) ë¶€ì„œ**ì—ëŠ” ì´ **1ëª…**ì˜ ì§ì›ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "- **Marketing (ë§ˆì¼€íŒ…) ë¶€ì„œ**ì—ëŠ” ì´ **2ëª…**ì˜ ì§ì›ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¦‰, ë¶€ì„œë³„ë¡œ ì§ì› ìˆ˜ë¥¼ ì§‘ê³„í•œ ê²°ê³¼ëŠ” ìœ„ì™€ ê°™ìœ¼ë©°, ê° ë¶€ì„œì˜ ì¸ì› ìˆ˜ë¥¼ í•œëˆˆì— í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# SQL ìƒì„±ê¸° State\n",
    "class SQLState(TypedDict):\n",
    "    question: str\n",
    "    schema: str\n",
    "    sql_query: str\n",
    "    result: str\n",
    "    error: Optional[str]\n",
    "    explanation: str\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •\n",
    "def setup_database():\n",
    "    conn = sqlite3.connect(':memory:')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # í…Œì´ë¸” ìƒì„±\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE employees (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            name TEXT,\n",
    "            department TEXT,\n",
    "            salary REAL,\n",
    "            hire_date DATE\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "        CREATE TABLE projects (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            name TEXT,\n",
    "            department TEXT,\n",
    "            budget REAL,\n",
    "            status TEXT\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    # ìƒ˜í”Œ ë°ì´í„°\n",
    "    employees = [\n",
    "        (1, 'ê¹€ì² ìˆ˜', 'Engineering', 70000, '2020-01-15'),\n",
    "        (2, 'ì´ì˜í¬', 'Marketing', 65000, '2019-03-20'),\n",
    "        (3, 'ë°•ë¯¼ìˆ˜', 'Engineering', 80000, '2018-07-10'),\n",
    "        (4, 'ì •ìˆ˜ì§„', 'HR', 60000, '2021-02-01'),\n",
    "        (5, 'í™ê¸¸ë™', 'Marketing', 72000, '2019-11-15')\n",
    "    ]\n",
    "    \n",
    "    projects = [\n",
    "        (1, 'Website Redesign', 'Marketing', 50000, 'Active'),\n",
    "        (2, 'Mobile App', 'Engineering', 150000, 'Active'),\n",
    "        (3, 'Data Pipeline', 'Engineering', 80000, 'Completed'),\n",
    "        (4, 'Training Program', 'HR', 30000, 'Planning')\n",
    "    ]\n",
    "    \n",
    "    cursor.executemany('INSERT INTO employees VALUES (?, ?, ?, ?, ?)', employees)\n",
    "    cursor.executemany('INSERT INTO projects VALUES (?, ?, ?, ?, ?)', projects)\n",
    "    conn.commit()\n",
    "    \n",
    "    return conn\n",
    "\n",
    "# ì „ì—­ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°\n",
    "GLOBAL_CONN = None\n",
    "\n",
    "def get_connection():\n",
    "    \"\"\"ì „ì—­ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê´€ë¦¬\"\"\"\n",
    "    global GLOBAL_CONN\n",
    "    if GLOBAL_CONN is None:\n",
    "        GLOBAL_CONN = setup_database()\n",
    "    return GLOBAL_CONN\n",
    "\n",
    "# SQL ìƒì„± ë…¸ë“œ\n",
    "def generate_sql(state: SQLState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒ ìŠ¤í‚¤ë§ˆë¥¼ ê°€ì§„ ë°ì´í„°ë² ì´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤:\n",
    "    \n",
    "    {state['schema']}\n",
    "    \n",
    "    ì‚¬ìš©ì ì§ˆë¬¸: {state['question']}\n",
    "    \n",
    "    ìœ„ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "    ì¿¼ë¦¬ë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    sql_query = response.content.strip()\n",
    "    sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    \n",
    "    state[\"sql_query\"] = sql_query\n",
    "    return state\n",
    "\n",
    "# SQL ì‹¤í–‰ ë…¸ë“œ (ìˆ˜ì •ë¨)\n",
    "def execute_sql(state: SQLState):\n",
    "    \"\"\"SQL ì‹¤í–‰ ë…¸ë“œ - ì „ì—­ ì—°ê²° ì‚¬ìš©\"\"\"\n",
    "    conn = get_connection()  # ì „ì—­ ì—°ê²° ì‚¬ìš©\n",
    "    \n",
    "    try:\n",
    "        result = pd.read_sql_query(state[\"sql_query\"], conn)\n",
    "        state[\"result\"] = result.to_string()\n",
    "        state[\"error\"] = None\n",
    "    except Exception as e:\n",
    "        state[\"error\"] = str(e)\n",
    "        state[\"result\"] = \"\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "# ê²°ê³¼ ì„¤ëª… ë…¸ë“œ\n",
    "def explain_result(state: SQLState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    \n",
    "    if state.get(\"error\"):\n",
    "        state[\"explanation\"] = f\"ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {state['error']}\"\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "        ì‚¬ìš©ì ì§ˆë¬¸: {state['question']}\n",
    "        ì‹¤í–‰ëœ SQL: {state['sql_query']}\n",
    "        ê²°ê³¼:\n",
    "        {state['result']}\n",
    "        \n",
    "        ìœ„ ê²°ê³¼ë¥¼ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke(prompt)\n",
    "        state[\"explanation\"] = response.content\n",
    "    \n",
    "    return state\n",
    "\n",
    "# SQL ìƒì„±ê¸° ê·¸ë˜í”„\n",
    "def create_sql_generator():\n",
    "    workflow = StateGraph(SQLState)\n",
    "    \n",
    "    # ë…¸ë“œ ì¶”ê°€\n",
    "    workflow.add_node(\"generate\", generate_sql)\n",
    "    workflow.add_node(\"execute\", execute_sql)\n",
    "    workflow.add_node(\"explain\", explain_result)\n",
    "    \n",
    "    # ì—£ì§€ ì¶”ê°€\n",
    "    workflow.set_entry_point(\"generate\")\n",
    "    workflow.add_edge(\"generate\", \"execute\")\n",
    "    workflow.add_edge(\"execute\", \"explain\")\n",
    "    workflow.add_edge(\"explain\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "sql_generator = create_sql_generator()\n",
    "\n",
    "# ìŠ¤í‚¤ë§ˆ ì •ë³´\n",
    "schema = \"\"\"\n",
    "employees í…Œì´ë¸”:\n",
    "- id: INTEGER (PRIMARY KEY)\n",
    "- name: TEXT\n",
    "- department: TEXT\n",
    "- salary: REAL\n",
    "- hire_date: DATE\n",
    "\n",
    "projects í…Œì´ë¸”:\n",
    "- id: INTEGER (PRIMARY KEY)\n",
    "- name: TEXT\n",
    "- department: TEXT\n",
    "- budget: REAL\n",
    "- status: TEXT\n",
    "\"\"\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤\n",
    "questions = [\n",
    "    \"Engineering ë¶€ì„œì˜ í‰ê·  ê¸‰ì—¬ëŠ”?\",\n",
    "    \"ê°€ì¥ ë†’ì€ ê¸‰ì—¬ë¥¼ ë°›ëŠ” ì§ì›ì€?\",\n",
    "    \"Active ìƒíƒœì¸ í”„ë¡œì íŠ¸ë“¤ì˜ ì´ ì˜ˆì‚°ì€?\",\n",
    "    \"ë¶€ì„œë³„ ì§ì› ìˆ˜ëŠ”?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nì§ˆë¬¸: {question}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # connectionì„ stateì— í¬í•¨ì‹œí‚¤ì§€ ì•Šê³ , ì „ì—­ ì—°ê²° ì‚¬ìš©\n",
    "    result = sql_generator.invoke({\n",
    "        \"question\": question,\n",
    "        \"schema\": schema\n",
    "    })\n",
    "    \n",
    "    print(f\"SQL: {result['sql_query']}\")\n",
    "    print(f\"\\nê²°ê³¼:\\n{result['result']}\")\n",
    "    print(f\"\\nì„¤ëª…: {result['explanation']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Source RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ì§ˆë¬¸: Pythonì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "ì„ íƒëœ ì†ŒìŠ¤: [<SourceType.WEB: 'web'>, <SourceType.DOCUMENT: 'document'>]\n",
      "ì´ìœ : Pythonì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì •ë³´ì™€ ì •ì˜ëŠ” ì›¹ì—ì„œ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆìœ¼ë©°, ê°€ì´ë“œì™€ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ëŠ” ë¬¸ì„œì—ì„œ ì œê³µë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ëœ ì†ŒìŠ¤: web\n",
      "\n",
      "ë‹µë³€:\n",
      "Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ì´ëŠ” ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° íŒ¨ëŸ¬ë‹¤ì„ì„ ì§€ì›í•˜ë©°, ì½”ë“œì˜ ê°€ë…ì„±ì´ ë†’ê³ , ë°°ìš°ê¸° ì‰¬ìš´ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¶œì²˜: [web] Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\n",
      "\n",
      "============================================================\n",
      "ì§ˆë¬¸: Python ê°œë°œì ì—°ë´‰ì€ ì–¼ë§ˆì¸ê°€ìš”?\n",
      "\n",
      "ì„ íƒëœ ì†ŒìŠ¤: [<SourceType.WEB: 'web'>, <SourceType.DATABASE: 'database'>]\n",
      "ì´ìœ : ì›¹ ì†ŒìŠ¤ëŠ” Python ê°œë°œì ì—°ë´‰ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì •ë³´ì™€ ê°œë…ì„ ì œê³µí•  ìˆ˜ ìˆìœ¼ë©°, ë°ì´í„°ë² ì´ìŠ¤ ì†ŒìŠ¤ëŠ” ì—°ë´‰ì— ëŒ€í•œ í†µê³„ì™€ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ëœ ì†ŒìŠ¤: web\n",
      "\n",
      "ë‹µë³€:\n",
      "Python ê°œë°œìì˜ ì—°ë´‰ì€ ì§€ì—­, ê²½ë ¥, ê¸°ìˆ  ìŠ¤íƒ ë“±ì— ë”°ë¼ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ì •í™•í•œ ê¸ˆì•¡ì„ ì œì‹œí•˜ê¸°ëŠ” ì–´ë µìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë¯¸êµ­ì—ì„œëŠ” Python ê°œë°œìì˜ í‰ê·  ì—°ë´‰ì´ ì•½ 80,000ë‹¬ëŸ¬ì—ì„œ 120,000ë‹¬ëŸ¬ ì‚¬ì´ë¡œ ë³´ê³ ë˜ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ì—ì„œëŠ” ê²½ë ¥ì— ë”°ë¼ 4,000ë§Œ ì›ì—ì„œ 8,000ë§Œ ì› ì´ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì •ë³´ëŠ” íŠ¹ì • ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì§ì ‘ í™•ì¸í•œ ê²ƒì´ ì•„ë‹ˆë¯€ë¡œ, ìµœì‹  ì—°ë´‰ ì •ë³´ë¥¼ ì–»ìœ¼ë ¤ë©´ êµ¬ì§ ì‚¬ì´íŠ¸ë‚˜ ì—°ë´‰ ì¡°ì‚¬ ì‚¬ì´íŠ¸ë¥¼ ì°¸ê³ í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì°¸ê³ í•œ ì†ŒìŠ¤:\n",
      "- [web] Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\n",
      "- [web] DjangoëŠ” Pythonìœ¼ë¡œ ì‘ì„±ëœ ì˜¤í”ˆì†ŒìŠ¤ ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "============================================================\n",
      "ì§ˆë¬¸: ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ëŠ” ë°©ë²•ì€?\n",
      "\n",
      "ì„ íƒëœ ì†ŒìŠ¤: [<SourceType.WEB: 'web'>, <SourceType.DOCUMENT: 'document'>]\n",
      "ì´ìœ : ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ì„œëŠ” ì¼ë°˜ì ì¸ ì •ë³´ì™€ ê°œë…ì„ ì œê³µí•˜ëŠ” ì›¹ ìë£Œì™€, êµ¬ì²´ì ì¸ ê°€ì´ë“œì™€ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë¥¼ í¬í•¨í•˜ëŠ” ë¬¸ì„œ ìë£Œê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ëœ ì†ŒìŠ¤: web\n",
      "\n",
      "ë‹µë³€:\n",
      "ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ë¬¸ì œ ì •ì˜**: í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œë¥¼ ëª…í™•íˆ ì •ì˜í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì˜ˆì¸¡, ë¶„ë¥˜, êµ°ì§‘í™” ë“±ì˜ ëª©í‘œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ë°ì´í„° ìˆ˜ì§‘**: ë¬¸ì œ í•´ê²°ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ë°ì´í„°ëŠ” ì›¹ ìŠ¤í¬ë˜í•‘, ê³µê°œ ë°ì´í„°ì…‹, ë˜ëŠ” ê¸°ì—… ë‚´ë¶€ ë°ì´í„° ë“± ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ìˆ˜ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ë°ì´í„° ì „ì²˜ë¦¬**: ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³ , ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ì´ìƒì¹˜ ì œê±°, ë°ì´í„° ë³€í™˜ ë“±ì˜ ì „ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **ëª¨ë¸ ì„ íƒ**: ë¬¸ì œì— ì í•©í•œ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íšŒê·€ ë¶„ì„, ì˜ì‚¬ê²°ì • ë‚˜ë¬´, ì‹ ê²½ë§ ë“±ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **ëª¨ë¸ í•™ìŠµ**: ì„ íƒí•œ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¤ê³ , ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ëª¨ë¸ í‰ê°€**: í•™ìŠµí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ êµì°¨ ê²€ì¦, ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ë“±ì˜ ì§€í‘œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "7. **ëª¨ë¸ íŠœë‹**: í•„ìš”ì— ë”°ë¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ë° ëª¨ë¸ ê°œì„  ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "8. **ë°°í¬**: ìµœì¢… ëª¨ë¸ì„ ì‹¤ì œ í™˜ê²½ì— ë°°í¬í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "9. **ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜**: ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³ , í•„ìš”ì— ë”°ë¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ê³¼ì •ì—ì„œ Pythonê³¼ Djangoì™€ ê°™ì€ ì›¹ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì†ŒìŠ¤: [web] DjangoëŠ” Pythonìœ¼ë¡œ ì‘ì„±ëœ ì˜¤í”ˆì†ŒìŠ¤ ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. [web] Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\n",
      "\n",
      "============================================================\n",
      "ì§ˆë¬¸: GPT-4ì˜ ìŠ¤í™ì€?\n",
      "\n",
      "ì„ íƒëœ ì†ŒìŠ¤: [<SourceType.WEB: 'web'>, <SourceType.DOCUMENT: 'document'>, <SourceType.API: 'api'>]\n",
      "ì´ìœ : GPT-4ì˜ ìŠ¤í™ì— ëŒ€í•œ ì •ë³´ëŠ” ì¼ë°˜ì ì¸ ì •ë³´ì™€ ì •ì˜ë¥¼ í¬í•¨í•˜ëŠ” ì›¹ ìë£Œ, ìƒì„¸í•œ ì„¤ëª…ê³¼ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ë¬¸ì„œ, ê·¸ë¦¬ê³  ìµœì‹  ê¸°ìˆ  ìŠ¤í™ê³¼ ì—…ë°ì´íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” API ì •ë³´ë¥¼ í†µí•´ ì¢…í•©ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ëœ ì†ŒìŠ¤: web\n",
      "\n",
      "ë‹µë³€:\n",
      "ì£„ì†¡í•˜ì§€ë§Œ, GPT-4ì˜ ìŠ¤í™ì— ëŒ€í•œ ì •ë³´ëŠ” ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì œê°€ ê°€ì§„ ì •ë³´ëŠ” 2023ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„°ì— ê¸°ë°˜í•˜ê³  ìˆìœ¼ë©°, ì£¼ì–´ì§„ ì›¹ ì •ë³´ëŠ” Pythonê³¼ Djangoì— ê´€í•œ ë‚´ìš©ì…ë‹ˆë‹¤. \n",
      "\n",
      "- Python: 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\n",
      "- Django: Pythonìœ¼ë¡œ ì‘ì„±ëœ ì˜¤í”ˆì†ŒìŠ¤ ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì •ë³´ëŠ” ì›¹ì—ì„œ ìˆ˜ì§‘í•œ ê²ƒì…ë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from enum import Enum\n",
    "\n",
    "class SourceType(str, Enum):\n",
    "    WEB = \"web\"\n",
    "    DATABASE = \"database\"\n",
    "    DOCUMENT = \"document\"\n",
    "    API = \"api\"\n",
    "\n",
    "class MultiRAGState(TypedDict):\n",
    "    query: str\n",
    "    source_type: SourceType\n",
    "    retrieved_docs: list\n",
    "    answer: str\n",
    "    sources_used: list\n",
    "\n",
    "# ë‹¤ì–‘í•œ ì†ŒìŠ¤ ì‹œë®¬ë ˆì´ì…˜\n",
    "def create_multi_source_data():\n",
    "    \"\"\"ë‹¤ì–‘í•œ ì†ŒìŠ¤ì˜ ë°ì´í„° ìƒì„±\"\"\"\n",
    "    \n",
    "    # ì›¹ ë°ì´í„°\n",
    "    web_docs = [\n",
    "        Document(\n",
    "            page_content=\"Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\",\n",
    "            metadata={\"source\": \"web\", \"url\": \"python.org\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"DjangoëŠ” Pythonìœ¼ë¡œ ì‘ì„±ëœ ì˜¤í”ˆì†ŒìŠ¤ ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\",\n",
    "            metadata={\"source\": \"web\", \"url\": \"djangoproject.com\"}\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„°\n",
    "    db_docs = [\n",
    "        Document(\n",
    "            page_content=\"2024ë…„ ê¸°ì¤€ Python ê°œë°œì í‰ê·  ì—°ë´‰ì€ 8,500ë§Œì›ì…ë‹ˆë‹¤.\",\n",
    "            metadata={\"source\": \"database\", \"table\": \"salary_stats\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"ê°€ì¥ ì¸ê¸°ìˆëŠ” Python ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” NumPy, Pandas, TensorFlowì…ë‹ˆë‹¤.\",\n",
    "            metadata={\"source\": \"database\", \"table\": \"library_usage\"}\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # ë¬¸ì„œ ë°ì´í„°\n",
    "    doc_docs = [\n",
    "        Document(\n",
    "            page_content=\"ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•  ë•ŒëŠ” ë°ì´í„° ì „ì²˜ë¦¬ê°€ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤.\",\n",
    "            metadata={\"source\": \"document\", \"file\": \"ml_guide.pdf\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì‹œ ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë“œë¡­ì•„ì›ƒì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\",\n",
    "            metadata={\"source\": \"document\", \"file\": \"dl_best_practices.pdf\"}\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # API ë°ì´í„°\n",
    "    api_docs = [\n",
    "        Document(\n",
    "            page_content=\"OpenAI GPT-4ì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ëŠ” 128,000 í† í°ì…ë‹ˆë‹¤.\",\n",
    "            metadata={\"source\": \"api\", \"endpoint\": \"/models/gpt-4\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\",\n",
    "            metadata={\"source\": \"api\", \"endpoint\": \"/frameworks/langchain\"}\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    return web_docs + db_docs + doc_docs + api_docs\n",
    "\n",
    "# ì†ŒìŠ¤ ë¼ìš°í„°\n",
    "def route_query(state: MultiRAGState):\n",
    "    \"\"\"ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì†ŒìŠ¤ ê²°ì •\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    \n",
    "    class SourceDecision(BaseModel):\n",
    "        source_types: list[SourceType] = Field(description=\"ê²€ìƒ‰í•  ì†ŒìŠ¤ íƒ€ì…ë“¤\")\n",
    "        reasoning: str = Field(description=\"ì„ íƒ ì´ìœ \")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸: {state['query']}\n",
    "    \n",
    "    ì´ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ê²€ìƒ‰í•´ì•¼ í•  ì†ŒìŠ¤ íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”:\n",
    "    - web: ì¼ë°˜ì ì¸ ì •ë³´, ì •ì˜, ê°œë…\n",
    "    - database: í†µê³„, ìˆ˜ì¹˜, íŠ¸ë Œë“œ ë°ì´í„°\n",
    "    - document: ê°€ì´ë“œ, ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤, ìƒì„¸ ì„¤ëª…\n",
    "    - api: ê¸°ìˆ  ìŠ¤í™, API ì •ë³´, ìµœì‹  ì—…ë°ì´íŠ¸\n",
    "    \n",
    "    ì—¬ëŸ¬ ì†ŒìŠ¤ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SourceDecision)\n",
    "    decision = structured_llm.invoke(prompt)\n",
    "    \n",
    "    state[\"source_types\"] = decision.source_types\n",
    "    print(f\"ì„ íƒëœ ì†ŒìŠ¤: {decision.source_types}\")\n",
    "    print(f\"ì´ìœ : {decision.reasoning}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# ê²€ìƒ‰ ë…¸ë“œ\n",
    "def retrieve_from_sources(state: MultiRAGState):\n",
    "    \"\"\"ì„ íƒëœ ì†ŒìŠ¤ì—ì„œ ì •ë³´ ê²€ìƒ‰\"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    all_docs = create_multi_source_data()\n",
    "    \n",
    "    # ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "    vectorstore = FAISS.from_documents(all_docs, embeddings)\n",
    "    \n",
    "    # ì†ŒìŠ¤ë³„ í•„í„°ë§ ê²€ìƒ‰\n",
    "    retrieved = []\n",
    "    for source_type in state.get(\"source_types\", [SourceType.WEB]):\n",
    "        # ëª¨ë“  ë¬¸ì„œ ê²€ìƒ‰ í›„ ì†ŒìŠ¤ í•„í„°ë§\n",
    "        results = vectorstore.similarity_search(state[\"query\"], k=10)\n",
    "        filtered = [doc for doc in results if doc.metadata[\"source\"] == source_type.value]\n",
    "        retrieved.extend(filtered[:2])  # ê° ì†ŒìŠ¤ì—ì„œ ìµœëŒ€ 2ê°œ\n",
    "    \n",
    "    state[\"retrieved_docs\"] = retrieved\n",
    "    state[\"sources_used\"] = list(set([doc.metadata[\"source\"] for doc in retrieved]))\n",
    "    \n",
    "    return state\n",
    "\n",
    "# ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "def generate_multi_source_answer(state: MultiRAGState):\n",
    "    \"\"\"ê²€ìƒ‰ëœ ì •ë³´ë¡œ ë‹µë³€ ìƒì„±\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    \n",
    "    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"[{doc.metadata['source']}] {doc.page_content}\"\n",
    "        for doc in state[\"retrieved_docs\"]\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n",
    "    \n",
    "    {context}\n",
    "    \n",
    "    ì§ˆë¬¸: {state['query']}\n",
    "    \n",
    "    ë‹µë³€ ì‹œ ì‚¬ìš©í•œ ì†ŒìŠ¤ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    state[\"answer\"] = response.content\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Multi-RAG ì‹œìŠ¤í…œ ìƒì„±\n",
    "def create_multi_rag():\n",
    "    workflow = StateGraph(MultiRAGState)\n",
    "    \n",
    "    # ë…¸ë“œ ì¶”ê°€\n",
    "    workflow.add_node(\"route\", route_query)\n",
    "    workflow.add_node(\"retrieve\", retrieve_from_sources)\n",
    "    workflow.add_node(\"answer\", generate_multi_source_answer)\n",
    "    \n",
    "    # ì—£ì§€ ì¶”ê°€\n",
    "    workflow.set_entry_point(\"route\")\n",
    "    workflow.add_edge(\"route\", \"retrieve\")\n",
    "    workflow.add_edge(\"retrieve\", \"answer\")\n",
    "    workflow.add_edge(\"answer\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "multi_rag = create_multi_rag()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤\n",
    "test_queries = [\n",
    "    \"Pythonì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"Python ê°œë°œì ì—°ë´‰ì€ ì–¼ë§ˆì¸ê°€ìš”?\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ëŠ” ë°©ë²•ì€?\",\n",
    "    \"GPT-4ì˜ ìŠ¤í™ì€?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ì§ˆë¬¸: {query}\\n\")\n",
    "    \n",
    "    result = multi_rag.invoke({\"query\": query})\n",
    "    \n",
    "    print(f\"\\nì‚¬ìš©ëœ ì†ŒìŠ¤: {', '.join(result['sources_used'])}\")\n",
    "    print(f\"\\në‹µë³€:\\n{result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ê³ ê¸‰ ì›Œí¬í”Œë¡œìš° íŒ¨í„´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import Literal\n",
    "\n",
    "class WorkflowState(TypedDict):\n",
    "    task: str\n",
    "    complexity: Literal[\"simple\", \"medium\", \"complex\"]\n",
    "    steps: list\n",
    "    current_step: int\n",
    "    results: dict\n",
    "    final_output: str\n",
    "\n",
    "# ë³µì¡ë„ í‰ê°€\n",
    "def assess_complexity(state: WorkflowState):\n",
    "    \"\"\"ì‘ì—… ë³µì¡ë„ í‰ê°€\"\"\"\n",
    "    task = state[\"task\"].lower()\n",
    "    \n",
    "    # ê°„ë‹¨í•œ ë³µì¡ë„ í‰ê°€ ë¡œì§\n",
    "    if any(word in task for word in [\"ê°„ë‹¨\", \"ê¸°ë³¸\", \"í™•ì¸\"]):\n",
    "        state[\"complexity\"] = \"simple\"\n",
    "    elif any(word in task for word in [\"ë¶„ì„\", \"ë¹„êµ\", \"í‰ê°€\"]):\n",
    "        state[\"complexity\"] = \"medium\"\n",
    "    else:\n",
    "        state[\"complexity\"] = \"complex\"\n",
    "    \n",
    "    print(f\"ì‘ì—… ë³µì¡ë„: {state['complexity']}\")\n",
    "    return state\n",
    "\n",
    "# ì‘ì—… ê³„íš\n",
    "def plan_steps(state: WorkflowState):\n",
    "    \"\"\"ë³µì¡ë„ì— ë”°ë¥¸ ì‘ì—… ë‹¨ê³„ ê³„íš\"\"\"\n",
    "    \n",
    "    if state[\"complexity\"] == \"simple\":\n",
    "        state[\"steps\"] = [\"ì§ì ‘ ì‹¤í–‰\"]\n",
    "    elif state[\"complexity\"] == \"medium\":\n",
    "        state[\"steps\"] = [\"ë°ì´í„° ìˆ˜ì§‘\", \"ë¶„ì„\", \"ê²°ê³¼ ì •ë¦¬\"]\n",
    "    else:\n",
    "        state[\"steps\"] = [\"ìš”êµ¬ì‚¬í•­ ë¶„ì„\", \"ë°ì´í„° ìˆ˜ì§‘\", \"ì²˜ë¦¬\", \"ê²€ì¦\", \"ìµœì¢… ì •ë¦¬\"]\n",
    "    \n",
    "    state[\"current_step\"] = 0\n",
    "    state[\"results\"] = {}\n",
    "    \n",
    "    print(f\"ê³„íšëœ ë‹¨ê³„: {state['steps']}\")\n",
    "    return state\n",
    "\n",
    "# ë‹¨ê³„ ì‹¤í–‰\n",
    "def execute_step(state: WorkflowState):\n",
    "    \"\"\"í˜„ì¬ ë‹¨ê³„ ì‹¤í–‰\"\"\"\n",
    "    if state[\"current_step\"] >= len(state[\"steps\"]):\n",
    "        return state\n",
    "    \n",
    "    current = state[\"steps\"][state[\"current_step\"]]\n",
    "    print(f\"ì‹¤í–‰ ì¤‘: {current}\")\n",
    "    \n",
    "    # ë‹¨ê³„ë³„ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜\n",
    "    state[\"results\"][current] = f\"{current} ì™„ë£Œ\"\n",
    "    state[\"current_step\"] += 1\n",
    "    \n",
    "    return state\n",
    "\n",
    "# ì™„ë£Œ í™•ì¸\n",
    "def check_completion(state: WorkflowState) -> Literal[\"execute\", \"finalize\"]:\n",
    "    \"\"\"ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ ì—¬ë¶€ í™•ì¸\"\"\"\n",
    "    if state[\"current_step\"] < len(state[\"steps\"]):\n",
    "        return \"execute\"\n",
    "    return \"finalize\"\n",
    "\n",
    "# ìµœì¢… ì •ë¦¬\n",
    "def finalize_results(state: WorkflowState):\n",
    "    \"\"\"ê²°ê³¼ ìµœì¢… ì •ë¦¬\"\"\"\n",
    "    state[\"final_output\"] = f\"\"\"\n",
    "    ì‘ì—…: {state['task']}\n",
    "    ë³µì¡ë„: {state['complexity']}\n",
    "    ì™„ë£Œëœ ë‹¨ê³„: {', '.join(state['steps'])}\n",
    "    ê²°ê³¼: {state['results']}\n",
    "    \"\"\"\n",
    "    return state\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ìƒì„±\n",
    "def create_adaptive_workflow():\n",
    "    workflow = StateGraph(WorkflowState)\n",
    "    \n",
    "    # ë…¸ë“œ ì¶”ê°€\n",
    "    workflow.add_node(\"assess\", assess_complexity)\n",
    "    workflow.add_node(\"plan\", plan_steps)\n",
    "    workflow.add_node(\"execute\", execute_step)\n",
    "    workflow.add_node(\"finalize\", finalize_results)\n",
    "    \n",
    "    # ì—£ì§€ ì¶”ê°€\n",
    "    workflow.set_entry_point(\"assess\")\n",
    "    workflow.add_edge(\"assess\", \"plan\")\n",
    "    workflow.add_edge(\"plan\", \"execute\")\n",
    "    \n",
    "    # ì¡°ê±´ë¶€ ì—£ì§€\n",
    "    workflow.add_conditional_edges(\n",
    "        \"execute\",\n",
    "        check_completion,\n",
    "        {\n",
    "            \"execute\": \"execute\",  # ì¬ê·€ì  ì‹¤í–‰\n",
    "            \"finalize\": \"finalize\"\n",
    "        }\n",
    "    )\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "adaptive_workflow = create_adaptive_workflow()\n",
    "\n",
    "# ë‹¤ì–‘í•œ ë³µì¡ë„ì˜ ì‘ì—… í…ŒìŠ¤íŠ¸\n",
    "tasks = [\n",
    "    \"ê°„ë‹¨í•œ ë°ì´í„° í™•ì¸\",\n",
    "    \"ì‚¬ìš©ì í–‰ë™ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ ë° ë°°í¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\"\n",
    "]\n",
    "\n",
    "for task in tasks:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ì‘ì—… ì‹œì‘: {task}\\n\")\n",
    "    \n",
    "    result = adaptive_workflow.invoke({\"task\": task})\n",
    "    \n",
    "    print(f\"\\nìµœì¢… ê²°ê³¼:\")\n",
    "    print(result[\"final_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹¤ìŠµ ê³¼ì œ\n",
    "\n",
    "1. ë‹¤êµ­ì–´ ì§€ì› ì±—ë´‡ êµ¬í˜„\n",
    "2. ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°ì„ ì²˜ë¦¬í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜\n",
    "3. ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸+ì´ë¯¸ì§€) ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì‹¤ìŠµ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
