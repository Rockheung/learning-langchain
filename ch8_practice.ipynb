{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Control Flow and State Management 실습\n",
    "\n",
    "이 노트북은 LangGraph의 고급 제어 흐름과 상태 관리 기법을 실습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = input(\"OpenAI API Key를 입력하세요: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Structured Output with State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Optional\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END, MessagesState\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "\n",
    "# 구조화된 출력 스키마들\n",
    "class TaskInfo(BaseModel):\n",
    "    title: str = Field(description=\"작업 제목\")\n",
    "    priority: str = Field(description=\"우선순위: high/medium/low\")\n",
    "    estimated_hours: float = Field(description=\"예상 소요 시간\")\n",
    "    dependencies: List[str] = Field(description=\"의존성 목록\")\n",
    "\n",
    "class ProjectPlan(BaseModel):\n",
    "    project_name: str = Field(description=\"프로젝트 이름\")\n",
    "    objectives: List[str] = Field(description=\"프로젝트 목표\")\n",
    "    tasks: List[TaskInfo] = Field(description=\"작업 목록\")\n",
    "    timeline: str = Field(description=\"전체 일정\")\n",
    "    risks: List[str] = Field(description=\"잠재적 위험\")\n",
    "\n",
    "# State 정의\n",
    "class StructuredState(MessagesState):\n",
    "    project_plan: Optional[ProjectPlan]\n",
    "    validation_results: Dict\n",
    "    optimization_suggestions: List[str]\n",
    "\n",
    "# 프로젝트 계획 생성 노드\n",
    "def generate_project_plan(state: StructuredState):\n",
    "    \"\"\"구조화된 프로젝트 계획 생성\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    query = messages[-1].content if messages else \"\"\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    structured_llm = llm.with_structured_output(ProjectPlan)\n",
    "    \n",
    "    planning_prompt = f\"\"\"\n",
    "    다음 요구사항에 대한 상세한 프로젝트 계획을 수립하세요:\n",
    "    \n",
    "    {query}\n",
    "    \n",
    "    체계적이고 실행 가능한 계획을 만드세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    project_plan = structured_llm.invoke(planning_prompt)\n",
    "    state[\"project_plan\"] = project_plan\n",
    "    \n",
    "    print(f\"프로젝트 계획 생성: {project_plan.project_name}\")\n",
    "    print(f\"작업 수: {len(project_plan.tasks)}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# 검증 노드\n",
    "def validate_plan(state: StructuredState):\n",
    "    \"\"\"계획의 유효성 검증\"\"\"\n",
    "    plan = state.get(\"project_plan\")\n",
    "    if not plan:\n",
    "        return state\n",
    "    \n",
    "    validation_results = {\n",
    "        \"has_objectives\": len(plan.objectives) > 0,\n",
    "        \"has_tasks\": len(plan.tasks) > 0,\n",
    "        \"reasonable_timeline\": len(plan.timeline) > 0,\n",
    "        \"risks_identified\": len(plan.risks) > 0,\n",
    "        \"total_hours\": sum(task.estimated_hours for task in plan.tasks),\n",
    "        \"high_priority_count\": sum(1 for task in plan.tasks if task.priority == \"high\")\n",
    "    }\n",
    "    \n",
    "    # 의존성 체크\n",
    "    all_task_titles = [task.title for task in plan.tasks]\n",
    "    invalid_dependencies = []\n",
    "    for task in plan.tasks:\n",
    "        for dep in task.dependencies:\n",
    "            if dep and dep not in all_task_titles:\n",
    "                invalid_dependencies.append(f\"{task.title} -> {dep}\")\n",
    "    \n",
    "    validation_results[\"invalid_dependencies\"] = invalid_dependencies\n",
    "    validation_results[\"is_valid\"] = (\n",
    "        validation_results[\"has_objectives\"] and\n",
    "        validation_results[\"has_tasks\"] and\n",
    "        len(invalid_dependencies) == 0\n",
    "    )\n",
    "    \n",
    "    state[\"validation_results\"] = validation_results\n",
    "    \n",
    "    print(f\"검증 완료: {'유효' if validation_results['is_valid'] else '무효'}\")\n",
    "    return state\n",
    "\n",
    "# 최적화 제안 노드\n",
    "def optimize_plan(state: StructuredState):\n",
    "    \"\"\"계획 최적화 제안\"\"\"\n",
    "    plan = state.get(\"project_plan\")\n",
    "    validation = state.get(\"validation_results\", {})\n",
    "    \n",
    "    suggestions = []\n",
    "    \n",
    "    if validation.get(\"total_hours\", 0) > 160:\n",
    "        suggestions.append(\"총 작업 시간이 160시간을 초과합니다. 작업을 단계별로 나누는 것을 고려하세요.\")\n",
    "    \n",
    "    if validation.get(\"high_priority_count\", 0) > len(plan.tasks) * 0.5:\n",
    "        suggestions.append(\"고우선순위 작업이 너무 많습니다. 우선순위를 재조정하세요.\")\n",
    "    \n",
    "    if len(plan.risks) < 3:\n",
    "        suggestions.append(\"더 많은 잠재적 위험을 식별하여 리스크 관리를 강화하세요.\")\n",
    "    \n",
    "    # 병렬 처리 가능 작업 찾기\n",
    "    parallel_tasks = []\n",
    "    for task in plan.tasks:\n",
    "        if not task.dependencies:\n",
    "            parallel_tasks.append(task.title)\n",
    "    \n",
    "    if len(parallel_tasks) > 1:\n",
    "        suggestions.append(f\"병렬 처리 가능: {', '.join(parallel_tasks)}\")\n",
    "    \n",
    "    state[\"optimization_suggestions\"] = suggestions\n",
    "    \n",
    "    return state\n",
    "\n",
    "# 구조화된 출력 그래프 생성\n",
    "def create_structured_output_graph():\n",
    "    workflow = StateGraph(StructuredState)\n",
    "    \n",
    "    workflow.add_node(\"generate\", generate_project_plan)\n",
    "    workflow.add_node(\"validate\", validate_plan)\n",
    "    workflow.add_node(\"optimize\", optimize_plan)\n",
    "    \n",
    "    workflow.set_entry_point(\"generate\")\n",
    "    workflow.add_edge(\"generate\", \"validate\")\n",
    "    workflow.add_edge(\"validate\", \"optimize\")\n",
    "    workflow.add_edge(\"optimize\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# 실행\n",
    "structured_graph = create_structured_output_graph()\n",
    "\n",
    "# 테스트\n",
    "project_requests = [\n",
    "    \"모바일 쇼핑 앱 개발 프로젝트\",\n",
    "    \"회사 웹사이트 리뉴얼 프로젝트\"\n",
    "]\n",
    "\n",
    "for request in project_requests:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"요청: {request}\\n\")\n",
    "    \n",
    "    result = structured_graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=request)]\n",
    "    })\n",
    "    \n",
    "    plan = result[\"project_plan\"]\n",
    "    print(f\"\\n프로젝트: {plan.project_name}\")\n",
    "    print(f\"목표: {', '.join(plan.objectives[:2])}...\")\n",
    "    print(f\"\\n작업 목록:\")\n",
    "    for task in plan.tasks[:3]:\n",
    "        print(f\"  - {task.title} ({task.priority}, {task.estimated_hours}h)\")\n",
    "    \n",
    "    print(f\"\\n최적화 제안:\")\n",
    "    for suggestion in result[\"optimization_suggestions\"]:\n",
    "        print(f\"  • {suggestion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Streaming Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import AsyncIterator\n",
    "\n",
    "# Streaming State\n",
    "class StreamingState(MessagesState):\n",
    "    current_chunk: str\n",
    "    accumulated_response: str\n",
    "    metadata: Dict\n",
    "\n",
    "# 스트리밍 노드\n",
    "async def stream_response(state: StreamingState):\n",
    "    \"\"\"스트리밍 응답 생성\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7, streaming=True)\n",
    "    \n",
    "    prompt = \"\"\"\n",
    "    사용자 질문에 대해 상세하고 도움이 되는 답변을 제공하세요.\n",
    "    단계별로 설명하고 예시를 포함하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    full_response = \"\"\n",
    "    async for chunk in llm.astream([{\"role\": \"system\", \"content\": prompt}] + messages):\n",
    "        if chunk.content:\n",
    "            full_response += chunk.content\n",
    "            yield chunk.content\n",
    "    \n",
    "    state[\"accumulated_response\"] = full_response\n",
    "    return state\n",
    "\n",
    "# 스트리밍 파이프라인\n",
    "class StreamingPipeline:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "    \n",
    "    async def process_with_progress(self, query: str):\n",
    "        \"\"\"진행 상황을 표시하며 처리\"\"\"\n",
    "        stages = [\n",
    "            (\"분석 중\", self._analyze),\n",
    "            (\"연구 중\", self._research),\n",
    "            (\"작성 중\", self._write),\n",
    "            (\"검토 중\", self._review)\n",
    "        ]\n",
    "        \n",
    "        results = {}\n",
    "        for stage_name, stage_func in stages:\n",
    "            print(f\"\\n[{stage_name}]\", end=\"\")\n",
    "            result = await stage_func(query, results)\n",
    "            results[stage_name] = result\n",
    "            \n",
    "            # 진행 표시\n",
    "            for _ in range(3):\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "                await asyncio.sleep(0.5)\n",
    "            print(\" 완료!\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    async def _analyze(self, query: str, context: dict) -> str:\n",
    "        response = await self.llm.ainvoke(f\"분석: {query}\")\n",
    "        return response.content[:100]\n",
    "    \n",
    "    async def _research(self, query: str, context: dict) -> str:\n",
    "        response = await self.llm.ainvoke(f\"연구: {query}\")\n",
    "        return response.content[:100]\n",
    "    \n",
    "    async def _write(self, query: str, context: dict) -> str:\n",
    "        analysis = context.get(\"분석 중\", \"\")\n",
    "        response = await self.llm.ainvoke(f\"작성: {query}\\n분석: {analysis}\")\n",
    "        return response.content[:200]\n",
    "    \n",
    "    async def _review(self, query: str, context: dict) -> str:\n",
    "        writing = context.get(\"작성 중\", \"\")\n",
    "        response = await self.llm.ainvoke(f\"검토: {writing[:50]}\")\n",
    "        return response.content[:100]\n",
    "\n",
    "# 실시간 스트리밍 시뮬레이션\n",
    "async def simulate_streaming():\n",
    "    \"\"\"실시간 스트리밍 시뮬레이션\"\"\"\n",
    "    queries = [\n",
    "        \"인공지능의 미래는?\",\n",
    "        \"효과적인 학습 방법은?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"질문: {query}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 스트리밍 응답\n",
    "        print(\"\\n스트리밍 응답:\")\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "        \n",
    "        full_response = \"\"\n",
    "        async for chunk in llm.astream(query):\n",
    "            if chunk.content:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "                full_response += chunk.content\n",
    "                await asyncio.sleep(0.01)  # 시각적 효과\n",
    "        \n",
    "        print(\"\\n\\n처리 완료!\")\n",
    "\n",
    "# 파이프라인 실행\n",
    "async def run_pipeline():\n",
    "    pipeline = StreamingPipeline()\n",
    "    \n",
    "    query = \"지속 가능한 발전을 위한 전략\"\n",
    "    print(f\"\\n질문: {query}\")\n",
    "    \n",
    "    results = await pipeline.process_with_progress(query)\n",
    "    \n",
    "    print(\"\\n최종 결과:\")\n",
    "    for stage, result in results.items():\n",
    "        print(f\"\\n[{stage}]\")\n",
    "        print(result[:100] + \"...\")\n",
    "\n",
    "# 실행\n",
    "print(\"스트리밍 데모 시작...\")\n",
    "await simulate_streaming()\n",
    "await run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interrupt and Human-in-the-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import Literal\n",
    "\n",
    "# Human-in-the-Loop State\n",
    "class HILState(MessagesState):\n",
    "    draft_response: str\n",
    "    human_feedback: Optional[str]\n",
    "    approval_status: Optional[str]\n",
    "    revision_count: int\n",
    "\n",
    "# 초안 생성 노드\n",
    "def generate_draft_response(state: HILState):\n",
    "    \"\"\"초안 응답 생성\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    state[\"draft_response\"] = response.content\n",
    "    state[\"revision_count\"] = state.get(\"revision_count\", 0)\n",
    "    \n",
    "    print(f\"\\n초안 생성 완료 (수정 {state['revision_count']}회)\")\n",
    "    print(f\"초안: {response.content[:200]}...\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# 인간 검토 시뮬레이션\n",
    "def simulate_human_review(draft: str) -> tuple[str, str]:\n",
    "    \"\"\"인간 검토 시뮬레이션 (실제로는 사용자 입력)\"\"\"\n",
    "    print(\"\\n=== 인간 검토 필요 ===\")\n",
    "    print(f\"초안: {draft[:300]}...\")\n",
    "    print(\"\\n옵션:\")\n",
    "    print(\"1. 승인 (approve)\")\n",
    "    print(\"2. 수정 요청 (revise)\")\n",
    "    print(\"3. 거부 (reject)\")\n",
    "    \n",
    "    # 시뮬레이션: 랜덤 선택\n",
    "    import random\n",
    "    choice = random.choice([\"approve\", \"revise\", \"revise\", \"approve\"])\n",
    "    \n",
    "    feedback = \"\"\n",
    "    if choice == \"revise\":\n",
    "        feedback = \"더 구체적인 예시를 추가하고 전문 용어를 줄여주세요.\"\n",
    "    \n",
    "    print(f\"\\n선택: {choice}\")\n",
    "    if feedback:\n",
    "        print(f\"피드백: {feedback}\")\n",
    "    \n",
    "    return choice, feedback\n",
    "\n",
    "# 인간 검토 노드\n",
    "def human_review(state: HILState):\n",
    "    \"\"\"인간 검토 단계\"\"\"\n",
    "    draft = state[\"draft_response\"]\n",
    "    \n",
    "    # 실제로는 여기서 중단하고 사용자 입력을 기다림\n",
    "    approval, feedback = simulate_human_review(draft)\n",
    "    \n",
    "    state[\"approval_status\"] = approval\n",
    "    state[\"human_feedback\"] = feedback\n",
    "    \n",
    "    return state\n",
    "\n",
    "# 수정 노드\n",
    "def revise_based_on_feedback(state: HILState):\n",
    "    \"\"\"피드백 기반 수정\"\"\"\n",
    "    draft = state[\"draft_response\"]\n",
    "    feedback = state[\"human_feedback\"]\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    \n",
    "    revision_prompt = f\"\"\"\n",
    "    원본 응답:\n",
    "    {draft}\n",
    "    \n",
    "    피드백:\n",
    "    {feedback}\n",
    "    \n",
    "    피드백을 반영하여 응답을 수정하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    revised = llm.invoke(revision_prompt)\n",
    "    state[\"draft_response\"] = revised.content\n",
    "    state[\"revision_count\"] += 1\n",
    "    \n",
    "    print(f\"\\n수정 완료 (총 {state['revision_count']}회 수정)\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# 라우팅 함수\n",
    "def route_after_review(state: HILState) -> Literal[\"revise\", \"finalize\", \"reject\"]:\n",
    "    \"\"\"검토 후 라우팅\"\"\"\n",
    "    status = state.get(\"approval_status\")\n",
    "    \n",
    "    if status == \"approve\":\n",
    "        return \"finalize\"\n",
    "    elif status == \"revise\":\n",
    "        if state.get(\"revision_count\", 0) >= 3:\n",
    "            print(\"최대 수정 횟수 도달\")\n",
    "            return \"finalize\"\n",
    "        return \"revise\"\n",
    "    else:\n",
    "        return \"reject\"\n",
    "\n",
    "# 최종화 노드\n",
    "def finalize_response(state: HILState):\n",
    "    \"\"\"응답 최종화\"\"\"\n",
    "    print(\"\\n✅ 응답 최종 승인됨\")\n",
    "    return {\"messages\": [AIMessage(content=state[\"draft_response\"])]}\n",
    "\n",
    "# 거부 노드\n",
    "def handle_rejection(state: HILState):\n",
    "    \"\"\"거부 처리\"\"\"\n",
    "    print(\"\\n❌ 응답 거부됨\")\n",
    "    return {\"messages\": [AIMessage(content=\"죄송합니다. 적절한 응답을 생성할 수 없습니다.\")]}\n",
    "\n",
    "# Human-in-the-Loop 그래프 생성\n",
    "def create_hil_graph():\n",
    "    workflow = StateGraph(HILState)\n",
    "    \n",
    "    # 노드 추가\n",
    "    workflow.add_node(\"generate\", generate_draft_response)\n",
    "    workflow.add_node(\"review\", human_review)\n",
    "    workflow.add_node(\"revise\", revise_based_on_feedback)\n",
    "    workflow.add_node(\"finalize\", finalize_response)\n",
    "    workflow.add_node(\"reject\", handle_rejection)\n",
    "    \n",
    "    # 플로우 정의\n",
    "    workflow.set_entry_point(\"generate\")\n",
    "    workflow.add_edge(\"generate\", \"review\")\n",
    "    workflow.add_edge(\"revise\", \"review\")\n",
    "    \n",
    "    # 조건부 라우팅\n",
    "    workflow.add_conditional_edges(\n",
    "        \"review\",\n",
    "        route_after_review,\n",
    "        {\n",
    "            \"revise\": \"revise\",\n",
    "            \"finalize\": \"finalize\",\n",
    "            \"reject\": \"reject\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "    workflow.add_edge(\"reject\", END)\n",
    "    \n",
    "    # 체크포인터 추가\n",
    "    memory = MemorySaver()\n",
    "    return workflow.compile(checkpointer=memory)\n",
    "\n",
    "# 실행\n",
    "hil_graph = create_hil_graph()\n",
    "\n",
    "# 테스트\n",
    "queries = [\n",
    "    \"복잡한 프로젝트를 관리하는 방법\",\n",
    "    \"AI 윤리에 대한 고찰\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"질문: {query}\")\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": f\"session_{query[:10]}\"}}\n",
    "    \n",
    "    result = hil_graph.invoke(\n",
    "        {\"messages\": [HumanMessage(content=query)]},\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n최종 응답:\")\n",
    "    print(result[\"messages\"][-1].content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. State Editing and Forking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Any\n",
    "\n",
    "# 버전 관리 State\n",
    "class VersionedState(MessagesState):\n",
    "    version: int\n",
    "    branch_name: str\n",
    "    history: List[Dict[str, Any]]\n",
    "    current_data: Dict\n",
    "    forks: List[str]\n",
    "\n",
    "# State 버전 관리자\n",
    "class StateVersionManager:\n",
    "    def __init__(self):\n",
    "        self.branches = {}\n",
    "        self.current_branch = \"main\"\n",
    "    \n",
    "    def save_state(self, state: Dict, branch: str = None) -> str:\n",
    "        \"\"\"현재 상태 저장\"\"\"\n",
    "        branch = branch or self.current_branch\n",
    "        \n",
    "        if branch not in self.branches:\n",
    "            self.branches[branch] = []\n",
    "        \n",
    "        version = len(self.branches[branch])\n",
    "        snapshot = {\n",
    "            \"version\": version,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"state\": copy.deepcopy(state)\n",
    "        }\n",
    "        \n",
    "        self.branches[branch].append(snapshot)\n",
    "        return f\"{branch}:v{version}\"\n",
    "    \n",
    "    def fork_state(self, from_branch: str, to_branch: str, version: int = -1) -> Dict:\n",
    "        \"\"\"상태 포크\"\"\"\n",
    "        if from_branch not in self.branches:\n",
    "            raise ValueError(f\"Branch {from_branch} not found\")\n",
    "        \n",
    "        source_state = self.branches[from_branch][version][\"state\"]\n",
    "        forked_state = copy.deepcopy(source_state)\n",
    "        \n",
    "        # 새 브랜치 생성\n",
    "        self.branches[to_branch] = [{\n",
    "            \"version\": 0,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"state\": forked_state,\n",
    "            \"forked_from\": f\"{from_branch}:v{version}\"\n",
    "        }]\n",
    "        \n",
    "        return forked_state\n",
    "    \n",
    "    def rollback(self, branch: str, version: int) -> Dict:\n",
    "        \"\"\"특정 버전으로 롤백\"\"\"\n",
    "        if branch not in self.branches:\n",
    "            raise ValueError(f\"Branch {branch} not found\")\n",
    "        \n",
    "        if version >= len(self.branches[branch]):\n",
    "            raise ValueError(f\"Version {version} not found\")\n",
    "        \n",
    "        return self.branches[branch][version][\"state\"]\n",
    "    \n",
    "    def merge_states(self, branch1: str, branch2: str, strategy: str = \"latest\") -> Dict:\n",
    "        \"\"\"두 브랜치 병합\"\"\"\n",
    "        state1 = self.branches[branch1][-1][\"state\"]\n",
    "        state2 = self.branches[branch2][-1][\"state\"]\n",
    "        \n",
    "        if strategy == \"latest\":\n",
    "            # 가장 최근 것 선택\n",
    "            time1 = self.branches[branch1][-1][\"timestamp\"]\n",
    "            time2 = self.branches[branch2][-1][\"timestamp\"]\n",
    "            return state1 if time1 > time2 else state2\n",
    "        elif strategy == \"combine\":\n",
    "            # 두 상태 결합\n",
    "            merged = copy.deepcopy(state1)\n",
    "            for key, value in state2.items():\n",
    "                if key not in merged:\n",
    "                    merged[key] = value\n",
    "                elif isinstance(value, list) and isinstance(merged[key], list):\n",
    "                    merged[key].extend(value)\n",
    "            return merged\n",
    "        \n",
    "        return state1\n",
    "\n",
    "# State 편집 노드들\n",
    "def edit_state_node(state: VersionedState, manager: StateVersionManager):\n",
    "    \"\"\"상태 편집\"\"\"\n",
    "    # 현재 상태 저장\n",
    "    version_id = manager.save_state(state, state.get(\"branch_name\", \"main\"))\n",
    "    \n",
    "    # 상태 수정\n",
    "    state[\"version\"] = state.get(\"version\", 0) + 1\n",
    "    state[\"current_data\"][\"edited\"] = True\n",
    "    state[\"current_data\"][\"edit_time\"] = datetime.now().isoformat()\n",
    "    \n",
    "    # 히스토리 추가\n",
    "    if \"history\" not in state:\n",
    "        state[\"history\"] = []\n",
    "    state[\"history\"].append({\n",
    "        \"action\": \"edit\",\n",
    "        \"version_id\": version_id,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "    \n",
    "    print(f\"상태 편집 완료: {version_id}\")\n",
    "    return state\n",
    "\n",
    "def fork_workflow(state: VersionedState, manager: StateVersionManager, fork_name: str):\n",
    "    \"\"\"워크플로우 포크\"\"\"\n",
    "    current_branch = state.get(\"branch_name\", \"main\")\n",
    "    \n",
    "    # 포크 생성\n",
    "    forked_state = manager.fork_state(current_branch, fork_name)\n",
    "    \n",
    "    # 포크 정보 업데이트\n",
    "    forked_state[\"branch_name\"] = fork_name\n",
    "    forked_state[\"version\"] = 0\n",
    "    \n",
    "    if \"forks\" not in state:\n",
    "        state[\"forks\"] = []\n",
    "    state[\"forks\"].append(fork_name)\n",
    "    \n",
    "    print(f\"포크 생성: {current_branch} -> {fork_name}\")\n",
    "    return forked_state\n",
    "\n",
    "# 실험적 워크플로우\n",
    "class ExperimentalWorkflow:\n",
    "    def __init__(self):\n",
    "        self.manager = StateVersionManager()\n",
    "        self.experiments = {}\n",
    "    \n",
    "    def run_experiment(self, name: str, initial_state: Dict):\n",
    "        \"\"\"실험 실행\"\"\"\n",
    "        print(f\"\\n실험 시작: {name}\")\n",
    "        \n",
    "        # 초기 상태 저장\n",
    "        self.manager.save_state(initial_state, name)\n",
    "        \n",
    "        # 실험 단계들\n",
    "        stages = [\n",
    "            (\"preprocessing\", self._preprocess),\n",
    "            (\"analysis\", self._analyze),\n",
    "            (\"optimization\", self._optimize)\n",
    "        ]\n",
    "        \n",
    "        current_state = initial_state\n",
    "        for stage_name, stage_func in stages:\n",
    "            print(f\"  단계: {stage_name}\")\n",
    "            \n",
    "            # 각 단계 전 상태 저장\n",
    "            self.manager.save_state(current_state, name)\n",
    "            \n",
    "            # 단계 실행\n",
    "            current_state = stage_func(current_state)\n",
    "            \n",
    "            # 실패 시 롤백 가능\n",
    "            if current_state.get(\"error\"):\n",
    "                print(f\"    오류 발생! 이전 상태로 롤백\")\n",
    "                current_state = self.manager.rollback(name, -2)\n",
    "                break\n",
    "        \n",
    "        self.experiments[name] = current_state\n",
    "        return current_state\n",
    "    \n",
    "    def _preprocess(self, state: Dict) -> Dict:\n",
    "        state[\"preprocessed\"] = True\n",
    "        state[\"data_size\"] = 1000\n",
    "        return state\n",
    "    \n",
    "    def _analyze(self, state: Dict) -> Dict:\n",
    "        if state.get(\"data_size\", 0) > 500:\n",
    "            state[\"analysis_result\"] = \"large_dataset\"\n",
    "        else:\n",
    "            state[\"analysis_result\"] = \"small_dataset\"\n",
    "        return state\n",
    "    \n",
    "    def _optimize(self, state: Dict) -> Dict:\n",
    "        if state.get(\"analysis_result\") == \"large_dataset\":\n",
    "            state[\"optimization\"] = \"parallel_processing\"\n",
    "        else:\n",
    "            state[\"optimization\"] = \"single_thread\"\n",
    "        return state\n",
    "    \n",
    "    def compare_experiments(self, exp1: str, exp2: str):\n",
    "        \"\"\"실험 결과 비교\"\"\"\n",
    "        result1 = self.experiments.get(exp1)\n",
    "        result2 = self.experiments.get(exp2)\n",
    "        \n",
    "        if not result1 or not result2:\n",
    "            return \"실험을 찾을 수 없습니다.\"\n",
    "        \n",
    "        print(f\"\\n실험 비교: {exp1} vs {exp2}\")\n",
    "        print(f\"{exp1}: {result1.get('optimization', 'N/A')}\")\n",
    "        print(f\"{exp2}: {result2.get('optimization', 'N/A')}\")\n",
    "\n",
    "# 실행\n",
    "print(\"State 버전 관리 데모\")\n",
    "\n",
    "# 버전 관리자 테스트\n",
    "manager = StateVersionManager()\n",
    "\n",
    "# 초기 상태\n",
    "initial_state = {\n",
    "    \"version\": 0,\n",
    "    \"branch_name\": \"main\",\n",
    "    \"current_data\": {\"value\": 100},\n",
    "    \"messages\": []\n",
    "}\n",
    "\n",
    "# 상태 편집\n",
    "state1 = edit_state_node(initial_state.copy(), manager)\n",
    "print(f\"버전 1: {state1['version']}\")\n",
    "\n",
    "# 포크 생성\n",
    "forked_state = fork_workflow(state1.copy(), manager, \"experiment-1\")\n",
    "print(f\"포크된 브랜치: {forked_state['branch_name']}\")\n",
    "\n",
    "# 실험 워크플로우\n",
    "print(\"\\n실험 워크플로우 테스트\")\n",
    "workflow = ExperimentalWorkflow()\n",
    "\n",
    "# 여러 실험 실행\n",
    "exp1_state = {\"experiment\": \"A\", \"parameters\": {\"learning_rate\": 0.01}}\n",
    "exp2_state = {\"experiment\": \"B\", \"parameters\": {\"learning_rate\": 0.001}}\n",
    "\n",
    "result1 = workflow.run_experiment(\"exp_A\", exp1_state)\n",
    "result2 = workflow.run_experiment(\"exp_B\", exp2_state)\n",
    "\n",
    "# 실험 비교\n",
    "workflow.compare_experiments(\"exp_A\", \"exp_B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Control Flow Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import time\n",
    "\n",
    "# 복잡한 제어 흐름 State\n",
    "class ComplexFlowState(TypedDict):\n",
    "    task: str\n",
    "    retry_count: int\n",
    "    max_retries: int\n",
    "    timeout: float\n",
    "    parallel_tasks: List[Dict]\n",
    "    conditional_branches: Dict\n",
    "    loop_counter: int\n",
    "    exit_condition: bool\n",
    "    results: List[Any]\n",
    "\n",
    "# 재시도 로직\n",
    "def retry_on_failure(func):\n",
    "    \"\"\"재시도 데코레이터\"\"\"\n",
    "    def wrapper(state: ComplexFlowState):\n",
    "        max_retries = state.get(\"max_retries\", 3)\n",
    "        retry_count = state.get(\"retry_count\", 0)\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                result = func(state)\n",
    "                state[\"retry_count\"] = 0\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                state[\"retry_count\"] = retry_count\n",
    "                print(f\"시도 {retry_count}/{max_retries} 실패: {e}\")\n",
    "                \n",
    "                if retry_count >= max_retries:\n",
    "                    print(\"최대 재시도 횟수 초과\")\n",
    "                    state[\"error\"] = str(e)\n",
    "                    return state\n",
    "                \n",
    "                time.sleep(2 ** retry_count)  # 지수 백오프\n",
    "        \n",
    "        return state\n",
    "    return wrapper\n",
    "\n",
    "# 타임아웃 처리\n",
    "def with_timeout(timeout_seconds: float):\n",
    "    \"\"\"타임아웃 데코레이터\"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(state: ComplexFlowState):\n",
    "            import signal\n",
    "            \n",
    "            def timeout_handler(signum, frame):\n",
    "                raise TimeoutError(f\"작업이 {timeout_seconds}초를 초과했습니다\")\n",
    "            \n",
    "            # 타임아웃 설정 (Unix 시스템에서만 작동)\n",
    "            try:\n",
    "                signal.signal(signal.SIGALRM, timeout_handler)\n",
    "                signal.alarm(int(timeout_seconds))\n",
    "                result = func(state)\n",
    "                signal.alarm(0)\n",
    "                return result\n",
    "            except:\n",
    "                # Windows 등에서는 간단한 시뮬레이션\n",
    "                import threading\n",
    "                result = [None]\n",
    "                \n",
    "                def run():\n",
    "                    result[0] = func(state)\n",
    "                \n",
    "                thread = threading.Thread(target=run)\n",
    "                thread.start()\n",
    "                thread.join(timeout_seconds)\n",
    "                \n",
    "                if thread.is_alive():\n",
    "                    print(f\"타임아웃: {timeout_seconds}초 초과\")\n",
    "                    state[\"timeout_occurred\"] = True\n",
    "                    return state\n",
    "                \n",
    "                return result[0]\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# 병렬 처리 노드\n",
    "async def parallel_execution(state: ComplexFlowState):\n",
    "    \"\"\"병렬 작업 실행\"\"\"\n",
    "    parallel_tasks = state.get(\"parallel_tasks\", [])\n",
    "    \n",
    "    async def execute_task(task: Dict):\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        response = await llm.ainvoke(task[\"prompt\"])\n",
    "        return {\n",
    "            \"task_id\": task[\"id\"],\n",
    "            \"result\": response.content[:100]\n",
    "        }\n",
    "    \n",
    "    # 모든 작업 동시 실행\n",
    "    import asyncio\n",
    "    results = await asyncio.gather(*[execute_task(task) for task in parallel_tasks])\n",
    "    \n",
    "    state[\"results\"] = results\n",
    "    print(f\"병렬 처리 완료: {len(results)}개 작업\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# 조건부 분기\n",
    "def conditional_branching(state: ComplexFlowState) -> str:\n",
    "    \"\"\"조건에 따른 분기\"\"\"\n",
    "    task = state.get(\"task\", \"\")\n",
    "    \n",
    "    conditions = {\n",
    "        \"simple\": lambda: len(task) < 50,\n",
    "        \"complex\": lambda: \"analyze\" in task.lower() or \"research\" in task.lower(),\n",
    "        \"urgent\": lambda: \"urgent\" in task.lower() or \"asap\" in task.lower()\n",
    "    }\n",
    "    \n",
    "    for branch_name, condition in conditions.items():\n",
    "        if condition():\n",
    "            print(f\"분기 선택: {branch_name}\")\n",
    "            return branch_name\n",
    "    \n",
    "    return \"default\"\n",
    "\n",
    "# 반복 처리\n",
    "def loop_until_condition(state: ComplexFlowState):\n",
    "    \"\"\"조건을 만족할 때까지 반복\"\"\"\n",
    "    loop_counter = state.get(\"loop_counter\", 0)\n",
    "    max_loops = 5\n",
    "    \n",
    "    while loop_counter < max_loops and not state.get(\"exit_condition\"):\n",
    "        print(f\"반복 {loop_counter + 1}/{max_loops}\")\n",
    "        \n",
    "        # 작업 수행\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        response = llm.invoke(f\"반복 {loop_counter}: {state.get('task', '')}\")\n",
    "        \n",
    "        # 종료 조건 체크\n",
    "        if \"complete\" in response.content.lower():\n",
    "            state[\"exit_condition\"] = True\n",
    "        \n",
    "        loop_counter += 1\n",
    "        state[\"loop_counter\"] = loop_counter\n",
    "    \n",
    "    if state.get(\"exit_condition\"):\n",
    "        print(\"조건 만족 - 반복 종료\")\n",
    "    else:\n",
    "        print(\"최대 반복 횟수 도달\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# 복잡한 제어 흐름 그래프\n",
    "def create_complex_flow_graph():\n",
    "    workflow = StateGraph(ComplexFlowState)\n",
    "    \n",
    "    # 재시도 가능한 노드\n",
    "    @retry_on_failure\n",
    "    def risky_operation(state):\n",
    "        import random\n",
    "        if random.random() < 0.5:\n",
    "            raise Exception(\"임의 오류 발생\")\n",
    "        state[\"risky_result\"] = \"성공\"\n",
    "        return state\n",
    "    \n",
    "    # 타임아웃이 있는 노드\n",
    "    @with_timeout(3.0)\n",
    "    def slow_operation(state):\n",
    "        time.sleep(1)  # 시뮬레이션\n",
    "        state[\"slow_result\"] = \"완료\"\n",
    "        return state\n",
    "    \n",
    "    # 노드 추가\n",
    "    workflow.add_node(\"risky\", risky_operation)\n",
    "    workflow.add_node(\"slow\", slow_operation)\n",
    "    workflow.add_node(\"loop\", loop_until_condition)\n",
    "    \n",
    "    # 분기별 처리 노드\n",
    "    def simple_handler(state):\n",
    "        state[\"result\"] = \"간단한 작업 완료\"\n",
    "        return state\n",
    "    \n",
    "    def complex_handler(state):\n",
    "        state[\"result\"] = \"복잡한 분석 완료\"\n",
    "        return state\n",
    "    \n",
    "    def urgent_handler(state):\n",
    "        state[\"result\"] = \"긴급 처리 완료\"\n",
    "        return state\n",
    "    \n",
    "    def default_handler(state):\n",
    "        state[\"result\"] = \"기본 처리 완료\"\n",
    "        return state\n",
    "    \n",
    "    workflow.add_node(\"simple\", simple_handler)\n",
    "    workflow.add_node(\"complex\", complex_handler)\n",
    "    workflow.add_node(\"urgent\", urgent_handler)\n",
    "    workflow.add_node(\"default\", default_handler)\n",
    "    \n",
    "    # 플로우 정의\n",
    "    workflow.set_entry_point(\"risky\")\n",
    "    workflow.add_edge(\"risky\", \"slow\")\n",
    "    workflow.add_edge(\"slow\", \"loop\")\n",
    "    \n",
    "    # 조건부 분기\n",
    "    workflow.add_conditional_edges(\n",
    "        \"loop\",\n",
    "        conditional_branching,\n",
    "        {\n",
    "            \"simple\": \"simple\",\n",
    "            \"complex\": \"complex\",\n",
    "            \"urgent\": \"urgent\",\n",
    "            \"default\": \"default\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 모든 분기를 END로\n",
    "    for node in [\"simple\", \"complex\", \"urgent\", \"default\"]:\n",
    "        workflow.add_edge(node, END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# 실행\n",
    "print(\"복잡한 제어 흐름 테스트\\n\")\n",
    "\n",
    "complex_graph = create_complex_flow_graph()\n",
    "\n",
    "# 다양한 시나리오 테스트\n",
    "test_scenarios = [\n",
    "    {\"task\": \"간단한 작업\", \"max_retries\": 3},\n",
    "    {\"task\": \"복잡한 데이터 analyze 작업\", \"max_retries\": 2},\n",
    "    {\"task\": \"urgent: 긴급 처리 필요\", \"max_retries\": 1}\n",
    "]\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"시나리오: {scenario['task']}\")\n",
    "    \n",
    "    result = complex_graph.invoke(scenario)\n",
    "    \n",
    "    print(f\"\\n최종 결과: {result.get('result', 'N/A')}\")\n",
    "    if result.get('risky_result'):\n",
    "        print(f\"위험 작업: {result['risky_result']}\")\n",
    "    if result.get('slow_result'):\n",
    "        print(f\"느린 작업: {result['slow_result']}\")\n",
    "    print(f\"반복 횟수: {result.get('loop_counter', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 과제\n",
    "\n",
    "1. 동적 라우팅과 상태 관리를 결합한 적응형 워크플로우\n",
    "2. 실시간 모니터링과 자동 복구 기능이 있는 안정적인 시스템\n",
    "3. 다중 사용자 협업을 지원하는 버전 관리 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 실습 코드를 작성하세요\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}