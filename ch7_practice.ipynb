{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Advanced LangGraph Patterns 실습\n",
    "\n",
    "이 노트북은 Reflection, Subgraphs, Supervisor 패턴 등 고급 기법을 실습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = input(\"OpenAI API Key를 입력하세요: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reflection Pattern (자기 성찰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Literal\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END, MessagesState\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Reflection State\n",
    "class ReflectionState(MessagesState):\n",
    "    draft: str\n",
    "    critique: str\n",
    "    revision_count: int\n",
    "    max_revisions: int\n",
    "    quality_score: float\n",
    "\n",
    "# 품질 평가 스키마\n",
    "class QualityAssessment(BaseModel):\n",
    "    score: float = Field(description=\"품질 점수 (0-10)\")\n",
    "    strengths: List[str] = Field(description=\"강점\")\n",
    "    weaknesses: List[str] = Field(description=\"약점\")\n",
    "    suggestions: List[str] = Field(description=\"개선 제안\")\n",
    "\n",
    "# 초안 생성 노드\n",
    "def generate_draft(state: ReflectionState):\n",
    "    \"\"\"초안 생성\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    query = messages[-1].content if messages else \"\"\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "    \n",
    "    draft_prompt = f\"\"\"\n",
    "    다음 요청에 대한 응답을 작성하세요:\n",
    "    \n",
    "    {query}\n",
    "    \n",
    "    명확하고 구조화된 답변을 제공하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(draft_prompt)\n",
    "    state[\"draft\"] = response.content\n",
    "    state[\"revision_count\"] = 0\n",
    "    state[\"max_revisions\"] = 3\n",
    "    \n",
    "    print(f\"초안 생성 완료 (길이: {len(response.content)}자)\")\n",
    "    return state\n",
    "\n",
    "# 비평 노드\n",
    "def critique_draft(state: ReflectionState):\n",
    "    \"\"\"초안을 비평하고 개선점 제시\"\"\"\n",
    "    draft = state[\"draft\"]\n",
    "    original_query = state[\"messages\"][-1].content\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    structured_llm = llm.with_structured_output(QualityAssessment)\n",
    "    \n",
    "    critique_prompt = f\"\"\"\n",
    "    원본 요청: {original_query}\n",
    "    \n",
    "    작성된 답변:\n",
    "    {draft}\n",
    "    \n",
    "    위 답변을 다음 기준으로 평가하세요:\n",
    "    1. 정확성: 정보가 정확한가?\n",
    "    2. 완전성: 모든 요구사항을 다루었는가?\n",
    "    3. 명확성: 이해하기 쉬운가?\n",
    "    4. 구조: 논리적으로 구성되었는가?\n",
    "    5. 유용성: 실제로 도움이 되는가?\n",
    "    \"\"\"\n",
    "    \n",
    "    assessment = structured_llm.invoke(critique_prompt)\n",
    "    \n",
    "    # 비평 텍스트 생성\n",
    "    critique = f\"\"\"\n",
    "    품질 점수: {assessment.score}/10\n",
    "    \n",
    "    강점:\n",
    "    {chr(10).join(f'- {s}' for s in assessment.strengths)}\n",
    "    \n",
    "    약점:\n",
    "    {chr(10).join(f'- {w}' for w in assessment.weaknesses)}\n",
    "    \n",
    "    개선 제안:\n",
    "    {chr(10).join(f'- {s}' for s in assessment.suggestions)}\n",
    "    \"\"\"\n",
    "    \n",
    "    state[\"critique\"] = critique\n",
    "    state[\"quality_score\"] = assessment.score\n",
    "    \n",
    "    print(f\"비평 완료 - 점수: {assessment.score}/10\")\n",
    "    return state\n",
    "\n",
    "# 수정 노드\n",
    "def revise_draft(state: ReflectionState):\n",
    "    \"\"\"비평을 바탕으로 초안 수정\"\"\"\n",
    "    draft = state[\"draft\"]\n",
    "    critique = state[\"critique\"]\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "    \n",
    "    revision_prompt = f\"\"\"\n",
    "    원본 답변:\n",
    "    {draft}\n",
    "    \n",
    "    비평 및 제안:\n",
    "    {critique}\n",
    "    \n",
    "    위 비평을 참고하여 답변을 개선하세요.\n",
    "    약점을 보완하고 제안사항을 반영하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    revised = llm.invoke(revision_prompt)\n",
    "    state[\"draft\"] = revised.content\n",
    "    state[\"revision_count\"] += 1\n",
    "    \n",
    "    print(f\"수정 {state['revision_count']}회 완료\")\n",
    "    return state\n",
    "\n",
    "# 완료 여부 결정\n",
    "def should_continue_revising(state: ReflectionState) -> Literal[\"critique\", \"end\"]:\n",
    "    \"\"\"추가 수정이 필요한지 결정\"\"\"\n",
    "    score = state.get(\"quality_score\", 0)\n",
    "    revision_count = state.get(\"revision_count\", 0)\n",
    "    max_revisions = state.get(\"max_revisions\", 3)\n",
    "    \n",
    "    # 품질이 충분하거나 최대 수정 횟수 도달\n",
    "    if score >= 8.0 or revision_count >= max_revisions:\n",
    "        return \"end\"\n",
    "    return \"critique\"\n",
    "\n",
    "# Reflection 그래프 생성\n",
    "def create_reflection_graph():\n",
    "    workflow = StateGraph(ReflectionState)\n",
    "    \n",
    "    # 노드 추가\n",
    "    workflow.add_node(\"generate\", generate_draft)\n",
    "    workflow.add_node(\"critique\", critique_draft)\n",
    "    workflow.add_node(\"revise\", revise_draft)\n",
    "    \n",
    "    # 플로우 정의\n",
    "    workflow.set_entry_point(\"generate\")\n",
    "    workflow.add_edge(\"generate\", \"critique\")\n",
    "    workflow.add_edge(\"revise\", \"critique\")\n",
    "    \n",
    "    # 조건부 엣지\n",
    "    workflow.add_conditional_edges(\n",
    "        \"critique\",\n",
    "        should_continue_revising,\n",
    "        {\n",
    "            \"critique\": \"revise\",\n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# 실행\n",
    "reflection_graph = create_reflection_graph()\n",
    "\n",
    "# 테스트\n",
    "queries = [\n",
    "    \"머신러닝과 딥러닝의 차이점을 설명해주세요.\",\n",
    "    \"효과적인 프로젝트 관리 방법론에 대해 설명해주세요.\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"질문: {query}\\n\")\n",
    "    \n",
    "    result = reflection_graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=query)]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n최종 답변 (점수: {result['quality_score']}/10):\")\n",
    "    print(result[\"draft\"])\n",
    "    print(f\"\\n총 수정 횟수: {result['revision_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Direct Subgraph Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# 서브그래프용 State\n",
    "class SubTaskState(TypedDict):\n",
    "    task: str\n",
    "    result: str\n",
    "    status: str\n",
    "\n",
    "# 메인 그래프 State\n",
    "class MainTaskState(TypedDict):\n",
    "    main_task: str\n",
    "    subtasks: List[str]\n",
    "    subtask_results: dict\n",
    "    final_result: str\n",
    "\n",
    "# 서브그래프 생성 함수\n",
    "def create_research_subgraph():\n",
    "    \"\"\"연구 작업을 수행하는 서브그래프\"\"\"\n",
    "    \n",
    "    def research(state: SubTaskState):\n",
    "        task = state[\"task\"]\n",
    "        print(f\"  [서브그래프] 연구 중: {task}\")\n",
    "        \n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        response = llm.invoke(f\"다음 주제에 대해 간단히 연구하세요: {task}\")\n",
    "        \n",
    "        state[\"result\"] = response.content\n",
    "        state[\"status\"] = \"researched\"\n",
    "        return state\n",
    "    \n",
    "    def validate(state: SubTaskState):\n",
    "        print(f\"  [서브그래프] 검증 중...\")\n",
    "        # 간단한 검증 로직\n",
    "        if len(state[\"result\"]) > 50:\n",
    "            state[\"status\"] = \"validated\"\n",
    "        else:\n",
    "            state[\"status\"] = \"needs_more_research\"\n",
    "        return state\n",
    "    \n",
    "    workflow = StateGraph(SubTaskState)\n",
    "    workflow.add_node(\"research\", research)\n",
    "    workflow.add_node(\"validate\", validate)\n",
    "    \n",
    "    workflow.set_entry_point(\"research\")\n",
    "    workflow.add_edge(\"research\", \"validate\")\n",
    "    workflow.add_edge(\"validate\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# 메인 그래프 노드들\n",
    "def decompose_task(state: MainTaskState):\n",
    "    \"\"\"작업을 서브태스크로 분해\"\"\"\n",
    "    main_task = state[\"main_task\"]\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    \n",
    "    decompose_prompt = f\"\"\"\n",
    "    다음 작업을 3개의 하위 작업으로 분해하세요:\n",
    "    {main_task}\n",
    "    \n",
    "    각 하위 작업을 한 줄로 작성하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(decompose_prompt)\n",
    "    subtasks = [line.strip() for line in response.content.split('\\n') if line.strip()][:3]\n",
    "    \n",
    "    state[\"subtasks\"] = subtasks\n",
    "    state[\"subtask_results\"] = {}\n",
    "    \n",
    "    print(f\"작업 분해 완료:\")\n",
    "    for i, task in enumerate(subtasks, 1):\n",
    "        print(f\"  {i}. {task}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def execute_subtasks(state: MainTaskState):\n",
    "    \"\"\"서브그래프를 사용하여 각 서브태스크 실행\"\"\"\n",
    "    research_graph = create_research_subgraph()\n",
    "    \n",
    "    print(\"\\n서브태스크 실행:\")\n",
    "    for subtask in state[\"subtasks\"]:\n",
    "        print(f\"\\n처리 중: {subtask}\")\n",
    "        \n",
    "        # 서브그래프 실행\n",
    "        subgraph_result = research_graph.invoke({\n",
    "            \"task\": subtask,\n",
    "            \"result\": \"\",\n",
    "            \"status\": \"pending\"\n",
    "        })\n",
    "        \n",
    "        state[\"subtask_results\"][subtask] = subgraph_result[\"result\"]\n",
    "    \n",
    "    return state\n",
    "\n",
    "def synthesize_results(state: MainTaskState):\n",
    "    \"\"\"서브태스크 결과들을 종합\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    \n",
    "    results_text = \"\\n\\n\".join([\n",
    "        f\"{task}:\\n{result}\"\n",
    "        for task, result in state[\"subtask_results\"].items()\n",
    "    ])\n",
    "    \n",
    "    synthesis_prompt = f\"\"\"\n",
    "    원본 작업: {state['main_task']}\n",
    "    \n",
    "    서브태스크 결과들:\n",
    "    {results_text}\n",
    "    \n",
    "    위 결과들을 종합하여 원본 작업에 대한 통합된 답변을 작성하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(synthesis_prompt)\n",
    "    state[\"final_result\"] = response.content\n",
    "    \n",
    "    return state\n",
    "\n",
    "# 메인 그래프 생성\n",
    "def create_main_with_subgraph():\n",
    "    workflow = StateGraph(MainTaskState)\n",
    "    \n",
    "    workflow.add_node(\"decompose\", decompose_task)\n",
    "    workflow.add_node(\"execute\", execute_subtasks)\n",
    "    workflow.add_node(\"synthesize\", synthesize_results)\n",
    "    \n",
    "    workflow.set_entry_point(\"decompose\")\n",
    "    workflow.add_edge(\"decompose\", \"execute\")\n",
    "    workflow.add_edge(\"execute\", \"synthesize\")\n",
    "    workflow.add_edge(\"synthesize\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# 실행\n",
    "main_graph = create_main_with_subgraph()\n",
    "\n",
    "# 테스트\n",
    "complex_tasks = [\n",
    "    \"스타트업을 성공적으로 운영하는 방법\",\n",
    "    \"기후 변화에 대응하는 개인의 역할\"\n",
    "]\n",
    "\n",
    "for task in complex_tasks:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"메인 작업: {task}\\n\")\n",
    "    \n",
    "    result = main_graph.invoke({\n",
    "        \"main_task\": task\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n최종 종합 결과:\")\n",
    "    print(result[\"final_result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Function Subgraph Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "# 재사용 가능한 서브그래프 팩토리\n",
    "class SubgraphFactory:\n",
    "    @staticmethod\n",
    "    def create_analysis_subgraph(analysis_type: str):\n",
    "        \"\"\"분석 유형에 따른 서브그래프 생성\"\"\"\n",
    "        \n",
    "        class AnalysisState(TypedDict):\n",
    "            data: str\n",
    "            analysis_type: str\n",
    "            analysis_result: dict\n",
    "            confidence: float\n",
    "        \n",
    "        def analyze(state: AnalysisState):\n",
    "            llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "            \n",
    "            prompts = {\n",
    "                \"sentiment\": \"감정 분석을 수행하세요 (긍정/부정/중립):\",\n",
    "                \"summary\": \"핵심 내용을 3줄로 요약하세요:\",\n",
    "                \"entities\": \"주요 엔티티(인물, 장소, 조직)를 추출하세요:\",\n",
    "                \"topics\": \"주요 주제를 식별하세요:\"\n",
    "            }\n",
    "            \n",
    "            prompt = prompts.get(analysis_type, \"분석을 수행하세요:\")\n",
    "            response = llm.invoke(f\"{prompt}\\n\\n{state['data']}\")\n",
    "            \n",
    "            state[\"analysis_result\"] = {\n",
    "                \"type\": analysis_type,\n",
    "                \"result\": response.content\n",
    "            }\n",
    "            return state\n",
    "        \n",
    "        def assess_confidence(state: AnalysisState):\n",
    "            # 간단한 신뢰도 평가\n",
    "            result_length = len(str(state[\"analysis_result\"].get(\"result\", \"\")))\n",
    "            state[\"confidence\"] = min(result_length / 100, 1.0)\n",
    "            return state\n",
    "        \n",
    "        workflow = StateGraph(AnalysisState)\n",
    "        workflow.add_node(\"analyze\", analyze)\n",
    "        workflow.add_node(\"assess\", assess_confidence)\n",
    "        \n",
    "        workflow.set_entry_point(\"analyze\")\n",
    "        workflow.add_edge(\"analyze\", \"assess\")\n",
    "        workflow.add_edge(\"assess\", END)\n",
    "        \n",
    "        return workflow.compile()\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_processing_subgraph(process_type: str):\n",
    "        \"\"\"데이터 처리 서브그래프 생성\"\"\"\n",
    "        \n",
    "        class ProcessState(TypedDict):\n",
    "            input_data: str\n",
    "            processed_data: str\n",
    "            metadata: dict\n",
    "        \n",
    "        def preprocess(state: ProcessState):\n",
    "            # 전처리\n",
    "            data = state[\"input_data\"]\n",
    "            if process_type == \"clean\":\n",
    "                data = data.strip().lower()\n",
    "            elif process_type == \"format\":\n",
    "                data = f\"Formatted: {data}\"\n",
    "            state[\"processed_data\"] = data\n",
    "            return state\n",
    "        \n",
    "        def add_metadata(state: ProcessState):\n",
    "            state[\"metadata\"] = {\n",
    "                \"process_type\": process_type,\n",
    "                \"timestamp\": \"2024-01-01\",\n",
    "                \"length\": len(state[\"processed_data\"])\n",
    "            }\n",
    "            return state\n",
    "        \n",
    "        workflow = StateGraph(ProcessState)\n",
    "        workflow.add_node(\"preprocess\", preprocess)\n",
    "        workflow.add_node(\"metadata\", add_metadata)\n",
    "        \n",
    "        workflow.set_entry_point(\"preprocess\")\n",
    "        workflow.add_edge(\"preprocess\", \"metadata\")\n",
    "        workflow.add_edge(\"metadata\", END)\n",
    "        \n",
    "        return workflow.compile()\n",
    "\n",
    "# 메인 파이프라인 State\n",
    "class PipelineState(TypedDict):\n",
    "    raw_text: str\n",
    "    analyses: List[dict]\n",
    "    processed_versions: List[dict]\n",
    "    final_report: str\n",
    "\n",
    "# 동적 서브그래프 실행 노드\n",
    "def run_multiple_analyses(state: PipelineState):\n",
    "    \"\"\"여러 분석 서브그래프 실행\"\"\"\n",
    "    text = state[\"raw_text\"]\n",
    "    analysis_types = [\"sentiment\", \"summary\", \"entities\", \"topics\"]\n",
    "    \n",
    "    state[\"analyses\"] = []\n",
    "    \n",
    "    print(\"분석 실행:\")\n",
    "    for analysis_type in analysis_types:\n",
    "        print(f\"  - {analysis_type} 분석 중...\")\n",
    "        \n",
    "        # 동적으로 서브그래프 생성 및 실행\n",
    "        subgraph = SubgraphFactory.create_analysis_subgraph(analysis_type)\n",
    "        result = subgraph.invoke({\n",
    "            \"data\": text,\n",
    "            \"analysis_type\": analysis_type\n",
    "        })\n",
    "        \n",
    "        state[\"analyses\"].append(result[\"analysis_result\"])\n",
    "    \n",
    "    return state\n",
    "\n",
    "def run_processing_pipeline(state: PipelineState):\n",
    "    \"\"\"처리 파이프라인 실행\"\"\"\n",
    "    text = state[\"raw_text\"]\n",
    "    process_types = [\"clean\", \"format\"]\n",
    "    \n",
    "    state[\"processed_versions\"] = []\n",
    "    \n",
    "    print(\"\\n처리 파이프라인:\")\n",
    "    for process_type in process_types:\n",
    "        print(f\"  - {process_type} 처리 중...\")\n",
    "        \n",
    "        subgraph = SubgraphFactory.create_processing_subgraph(process_type)\n",
    "        result = subgraph.invoke({\n",
    "            \"input_data\": text\n",
    "        })\n",
    "        \n",
    "        state[\"processed_versions\"].append({\n",
    "            \"type\": process_type,\n",
    "            \"data\": result[\"processed_data\"],\n",
    "            \"metadata\": result[\"metadata\"]\n",
    "        })\n",
    "    \n",
    "    return state\n",
    "\n",
    "def generate_report(state: PipelineState):\n",
    "    \"\"\"최종 보고서 생성\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    \n",
    "    analyses_text = \"\\n\".join([\n",
    "        f\"{a['type']}: {a['result']}\"\n",
    "        for a in state[\"analyses\"]\n",
    "    ])\n",
    "    \n",
    "    report_prompt = f\"\"\"\n",
    "    원본 텍스트에 대한 종합 분석 보고서를 작성하세요.\n",
    "    \n",
    "    분석 결과:\n",
    "    {analyses_text}\n",
    "    \n",
    "    간결하고 구조화된 보고서를 작성하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(report_prompt)\n",
    "    state[\"final_report\"] = response.content\n",
    "    \n",
    "    return state\n",
    "\n",
    "# 메인 파이프라인 생성\n",
    "def create_dynamic_pipeline():\n",
    "    workflow = StateGraph(PipelineState)\n",
    "    \n",
    "    workflow.add_node(\"analyze\", run_multiple_analyses)\n",
    "    workflow.add_node(\"process\", run_processing_pipeline)\n",
    "    workflow.add_node(\"report\", generate_report)\n",
    "    \n",
    "    workflow.set_entry_point(\"analyze\")\n",
    "    workflow.add_edge(\"analyze\", \"process\")\n",
    "    workflow.add_edge(\"process\", \"report\")\n",
    "    workflow.add_edge(\"report\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# 실행\n",
    "pipeline = create_dynamic_pipeline()\n",
    "\n",
    "# 테스트\n",
    "test_texts = [\n",
    "    \"\"\"인공지능은 현대 사회에 혁명적인 변화를 가져오고 있습니다. \n",
    "    의료, 교육, 금융 등 다양한 분야에서 AI의 활용이 증가하고 있으며,\n",
    "    이는 효율성 향상과 새로운 기회 창출로 이어지고 있습니다.\n",
    "    그러나 동시에 일자리 감소와 프라이버시 문제 등의 우려도 제기되고 있습니다.\"\"\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"원본 텍스트:\\n{text[:100]}...\\n\")\n",
    "    \n",
    "    result = pipeline.invoke({\"raw_text\": text})\n",
    "    \n",
    "    print(f\"\\n최종 보고서:\")\n",
    "    print(result[\"final_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Supervisor Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "import operator\n",
    "\n",
    "# Supervisor State\n",
    "class SupervisorState(TypedDict):\n",
    "    task: str\n",
    "    workers: List[str]\n",
    "    assignments: dict\n",
    "    worker_results: Annotated[List[dict], operator.add]\n",
    "    supervisor_summary: str\n",
    "    status: str\n",
    "\n",
    "# Worker 에이전트 생성\n",
    "def create_worker_agent(name: str, specialty: str):\n",
    "    \"\"\"특정 전문 분야를 가진 워커 에이전트 생성\"\"\"\n",
    "    \n",
    "    def worker_function(task: str) -> dict:\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "        \n",
    "        worker_prompt = f\"\"\"\n",
    "        당신은 {specialty} 전문가인 {name}입니다.\n",
    "        \n",
    "        다음 작업을 수행하세요:\n",
    "        {task}\n",
    "        \n",
    "        당신의 전문 분야 관점에서 답변하세요.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke(worker_prompt)\n",
    "        \n",
    "        return {\n",
    "            \"worker\": name,\n",
    "            \"specialty\": specialty,\n",
    "            \"task\": task,\n",
    "            \"result\": response.content\n",
    "        }\n",
    "    \n",
    "    return worker_function\n",
    "\n",
    "# Supervisor 노드\n",
    "def supervisor_assign_tasks(state: SupervisorState):\n",
    "    \"\"\"Supervisor가 작업을 워커들에게 할당\"\"\"\n",
    "    main_task = state[\"task\"]\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    \n",
    "    # 워커 정의\n",
    "    workers = [\n",
    "        {\"name\": \"Researcher\", \"specialty\": \"정보 수집 및 연구\"},\n",
    "        {\"name\": \"Analyst\", \"specialty\": \"데이터 분석 및 인사이트 도출\"},\n",
    "        {\"name\": \"Writer\", \"specialty\": \"문서 작성 및 편집\"}\n",
    "    ]\n",
    "    \n",
    "    state[\"workers\"] = [w[\"name\"] for w in workers]\n",
    "    \n",
    "    # 각 워커에게 작업 할당\n",
    "    assign_prompt = f\"\"\"\n",
    "    메인 작업: {main_task}\n",
    "    \n",
    "    이 작업을 다음 3명의 워커에게 할당하세요:\n",
    "    1. Researcher (정보 수집 전문)\n",
    "    2. Analyst (분석 전문)\n",
    "    3. Writer (작성 전문)\n",
    "    \n",
    "    각 워커에게 구체적인 하위 작업을 할당하세요.\n",
    "    JSON 형식으로 응답하세요: {{\"워커이름\": \"할당된 작업\"}}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(assign_prompt)\n",
    "    \n",
    "    # 간단한 파싱 (실제로는 구조화된 출력 사용)\n",
    "    assignments = {\n",
    "        \"Researcher\": f\"{main_task}에 대한 정보 수집\",\n",
    "        \"Analyst\": f\"{main_task}에 대한 분석\",\n",
    "        \"Writer\": f\"{main_task}에 대한 문서 작성\"\n",
    "    }\n",
    "    \n",
    "    state[\"assignments\"] = assignments\n",
    "    state[\"worker_results\"] = []\n",
    "    state[\"status\"] = \"assigned\"\n",
    "    \n",
    "    print(\"Supervisor: 작업 할당 완료\")\n",
    "    for worker, task in assignments.items():\n",
    "        print(f\"  - {worker}: {task}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def execute_worker_tasks(state: SupervisorState):\n",
    "    \"\"\"워커들이 할당된 작업 실행\"\"\"\n",
    "    assignments = state[\"assignments\"]\n",
    "    \n",
    "    # 워커 에이전트 생성\n",
    "    workers = {\n",
    "        \"Researcher\": create_worker_agent(\"Researcher\", \"정보 수집 및 연구\"),\n",
    "        \"Analyst\": create_worker_agent(\"Analyst\", \"데이터 분석 및 인사이트 도출\"),\n",
    "        \"Writer\": create_worker_agent(\"Writer\", \"문서 작성 및 편집\")\n",
    "    }\n",
    "    \n",
    "    print(\"\\n워커들이 작업 수행 중:\")\n",
    "    results = []\n",
    "    for worker_name, task in assignments.items():\n",
    "        print(f\"  - {worker_name} 작업 중...\")\n",
    "        worker = workers[worker_name]\n",
    "        result = worker(task)\n",
    "        results.append(result)\n",
    "    \n",
    "    state[\"worker_results\"] = results\n",
    "    state[\"status\"] = \"completed\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def supervisor_review_and_summarize(state: SupervisorState):\n",
    "    \"\"\"Supervisor가 결과 검토 및 최종 요약\"\"\"\n",
    "    worker_results = state[\"worker_results\"]\n",
    "    main_task = state[\"task\"]\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    \n",
    "    # 워커 결과 정리\n",
    "    results_text = \"\\n\\n\".join([\n",
    "        f\"{r['worker']} ({r['specialty']}):\\n{r['result']}\"\n",
    "        for r in worker_results\n",
    "    ])\n",
    "    \n",
    "    review_prompt = f\"\"\"\n",
    "    당신은 프로젝트 Supervisor입니다.\n",
    "    \n",
    "    메인 작업: {main_task}\n",
    "    \n",
    "    워커들의 작업 결과:\n",
    "    {results_text}\n",
    "    \n",
    "    위 결과들을 검토하고 통합하여 최종 보고서를 작성하세요.\n",
    "    각 워커의 기여를 인정하면서 일관된 결론을 도출하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(review_prompt)\n",
    "    state[\"supervisor_summary\"] = response.content\n",
    "    state[\"status\"] = \"reviewed\"\n",
    "    \n",
    "    print(\"\\nSupervisor: 검토 및 요약 완료\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Supervisor 패턴 그래프 생성\n",
    "def create_supervisor_graph():\n",
    "    workflow = StateGraph(SupervisorState)\n",
    "    \n",
    "    # 노드 추가\n",
    "    workflow.add_node(\"assign\", supervisor_assign_tasks)\n",
    "    workflow.add_node(\"execute\", execute_worker_tasks)\n",
    "    workflow.add_node(\"review\", supervisor_review_and_summarize)\n",
    "    \n",
    "    # 플로우 정의\n",
    "    workflow.set_entry_point(\"assign\")\n",
    "    workflow.add_edge(\"assign\", \"execute\")\n",
    "    workflow.add_edge(\"execute\", \"review\")\n",
    "    workflow.add_edge(\"review\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# 실행\n",
    "supervisor_graph = create_supervisor_graph()\n",
    "\n",
    "# 테스트\n",
    "tasks = [\n",
    "    \"신제품 출시 전략 수립\",\n",
    "    \"고객 만족도 향상 방안\",\n",
    "    \"디지털 전환 로드맵 작성\"\n",
    "]\n",
    "\n",
    "for task in tasks:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"메인 작업: {task}\\n\")\n",
    "    \n",
    "    result = supervisor_graph.invoke({\"task\": task})\n",
    "    \n",
    "    print(f\"\\n최종 Supervisor 보고서:\")\n",
    "    print(result[\"supervisor_summary\"])\n",
    "    \n",
    "    print(f\"\\n상태: {result['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 과제\n",
    "\n",
    "1. 다단계 Reflection이 있는 창의적 글쓰기 시스템\n",
    "2. 계층적 서브그래프를 활용한 복잡한 프로젝트 관리 시스템\n",
    "3. 동적 워커 할당이 가능한 적응형 Supervisor 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 실습 코드를 작성하세요\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}