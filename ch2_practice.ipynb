{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: 문서 로더와 벡터 저장소 실습\n",
    "\n",
    "이 노트북은 LangChain의 문서 로더, 텍스트 분할기, 임베딩, 벡터 저장소를 실습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = input(\"OpenAI API Key를 입력하세요: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 텍스트 파일 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 문서 수: 1\n",
      "문서 내용:\n",
      "LangChain은 언어 모델을 활용한 애플리케이션 개발 프레임워크입니다.\n",
      "다양한 컴포넌트를 제공하여 복잡한 AI 애플리케이션을 쉽게 만들 수 있습니다.\n",
      "문서 로더, 텍스트 분할기, 임베딩, 벡터 저장소 등의 기능을 제공합니다.\n",
      "메타데이터: {'source': 'sample.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 샘플 텍스트 파일 생성\n",
    "sample_text = \"\"\"LangChain은 언어 모델을 활용한 애플리케이션 개발 프레임워크입니다.\n",
    "다양한 컴포넌트를 제공하여 복잡한 AI 애플리케이션을 쉽게 만들 수 있습니다.\n",
    "문서 로더, 텍스트 분할기, 임베딩, 벡터 저장소 등의 기능을 제공합니다.\"\"\"\n",
    "\n",
    "with open(\"sample.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "# TextLoader 사용\n",
    "loader = TextLoader(\"sample.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"로드된 문서 수: {len(documents)}\")\n",
    "print(f\"문서 내용:\\n{documents[0].page_content}\")\n",
    "print(f\"메타데이터: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 웹 페이지 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 웹 문서 수: 1\n",
      "첫 500자:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Introduction | 🦜️🔗 LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) A...\n",
      "\n",
      "메타데이터: {'source': 'https://python.langchain.com/docs/introduction/', 'title': 'Introduction | 🦜️🔗 LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 웹 페이지 로드\n",
    "web_loader = WebBaseLoader(\"https://python.langchain.com/docs/introduction/\")\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "print(f\"로드된 웹 문서 수: {len(web_docs)}\")\n",
    "print(f\"첫 500자:\\n{web_docs[0].page_content[:500]}...\")\n",
    "print(f\"\\n메타데이터: {web_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PDF 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 페이지 수: 1\n",
      "첫 페이지 내용 (100자):\n",
      "Life in ancient Greece was centered around the polis, or city-state, which served as the heart of \n",
      "s...\n"
     ]
    }
   ],
   "source": [
    "# PDF 파일이 있는 경우 실행\n",
    "try:\n",
    "    from langchain_community.document_loaders import PyPDFLoader\n",
    "    \n",
    "    # test.pdf 파일이 있다면 로드\n",
    "    if os.path.exists(\"test.pdf\"):\n",
    "        pdf_loader = PyPDFLoader(\"test.pdf\")\n",
    "        pdf_docs = pdf_loader.load()\n",
    "        print(f\"PDF 페이지 수: {len(pdf_docs)}\")\n",
    "        print(f\"첫 페이지 내용 (100자):\\n{pdf_docs[0].page_content[:100]}...\")\n",
    "    else:\n",
    "        print(\"test.pdf 파일이 없습니다.\")\n",
    "except ImportError:\n",
    "    print(\"PyPDF 라이브러리가 설치되지 않았습니다. 'pip install pypdf'로 설치하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 재귀적 텍스트 분할기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크 수: 5\n",
      "\n",
      "청크 1 (54자):\n",
      "LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발을 위한 프레임워크입니다.\n",
      "--------------------------------------------------\n",
      "청크 2 (91자):\n",
      "주요 기능:\n",
      "1. 프롬프트 관리: 프롬프트 템플릿을 쉽게 만들고 관리할 수 있습니다.\n",
      "2. 체인: 여러 컴포넌트를 연결하여 복잡한 워크플로우를 구성할 수 있습니다.\n",
      "--------------------------------------------------\n",
      "청크 3 (69자):\n",
      "3. 에이전트: LLM이 도구를 사용하여 작업을 수행할 수 있게 합니다.\n",
      "4. 메모리: 대화 컨텍스트를 유지하고 관리합니다.\n",
      "--------------------------------------------------\n",
      "청크 4 (85자):\n",
      "LangChain의 장점:\n",
      "- 모듈성: 각 컴포넌트를 독립적으로 사용하거나 조합할 수 있습니다.\n",
      "- 확장성: 커스텀 컴포넌트를 쉽게 추가할 수 있습니다.\n",
      "--------------------------------------------------\n",
      "청크 5 (29자):\n",
      "- 통합: 다양한 LLM 제공자와 도구를 지원합니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 긴 텍스트 생성\n",
    "long_text = \"\"\"\n",
    "LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발을 위한 프레임워크입니다.\n",
    "\n",
    "주요 기능:\n",
    "1. 프롬프트 관리: 프롬프트 템플릿을 쉽게 만들고 관리할 수 있습니다.\n",
    "2. 체인: 여러 컴포넌트를 연결하여 복잡한 워크플로우를 구성할 수 있습니다.\n",
    "3. 에이전트: LLM이 도구를 사용하여 작업을 수행할 수 있게 합니다.\n",
    "4. 메모리: 대화 컨텍스트를 유지하고 관리합니다.\n",
    "\n",
    "LangChain의 장점:\n",
    "- 모듈성: 각 컴포넌트를 독립적으로 사용하거나 조합할 수 있습니다.\n",
    "- 확장성: 커스텀 컴포넌트를 쉽게 추가할 수 있습니다.\n",
    "- 통합: 다양한 LLM 제공자와 도구를 지원합니다.\n",
    "\"\"\"\n",
    "\n",
    "# 텍스트 분할기 생성\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# 텍스트 분할\n",
    "chunks = text_splitter.split_text(long_text)\n",
    "\n",
    "print(f\"분할된 청크 수: {len(chunks)}\\n\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"청크 {i} ({len(chunk)}자):\\n{chunk}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 코드 분할기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드 청크 수: 5\n",
      "\n",
      "코드 청크 1:\n",
      "def hello_world():\n",
      "    \"\"\"간단한 헬로 월드 함수\"\"\"\n",
      "    print(\"Hello, World!\")\n",
      "    return True\n",
      "--------------------------------------------------\n",
      "코드 청크 2:\n",
      "class Greeting:\n",
      "    \"\"\"인사말 클래스\"\"\"\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "--------------------------------------------------\n",
      "코드 청크 3:\n",
      "def say_hello(self):\n",
      "        \"\"\"인사하기\"\"\"\n",
      "        return f\"Hello, {self.name}!\"\n",
      "--------------------------------------------------\n",
      "코드 청크 4:\n",
      "def say_goodbye(self):\n",
      "        \"\"\"작별 인사\"\"\"\n",
      "        return f\"Goodbye, {self.name}!\"\n",
      "--------------------------------------------------\n",
      "코드 청크 5:\n",
      "if __name__ == \"__main__\":\n",
      "    hello_world()\n",
      "    greeter = Greeting(\"LangChain\")\n",
      "    print(greeter.say_hello())\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "# 파이썬 코드 예제\n",
    "python_code = '''\n",
    "def hello_world():\n",
    "    \"\"\"간단한 헬로 월드 함수\"\"\"\n",
    "    print(\"Hello, World!\")\n",
    "    return True\n",
    "\n",
    "class Greeting:\n",
    "    \"\"\"인사말 클래스\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def say_hello(self):\n",
    "        \"\"\"인사하기\"\"\"\n",
    "        return f\"Hello, {self.name}!\"\n",
    "    \n",
    "    def say_goodbye(self):\n",
    "        \"\"\"작별 인사\"\"\"\n",
    "        return f\"Goodbye, {self.name}!\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hello_world()\n",
    "    greeter = Greeting(\"LangChain\")\n",
    "    print(greeter.say_hello())\n",
    "'''\n",
    "\n",
    "# 파이썬 코드 분할기\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "code_chunks = python_splitter.split_text(python_code)\n",
    "\n",
    "print(f\"코드 청크 수: {len(code_chunks)}\\n\")\n",
    "for i, chunk in enumerate(code_chunks, 1):\n",
    "    print(f\"코드 청크 {i}:\\n{chunk}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 마크다운 분할기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마크다운 청크 수: 4\n",
      "\n",
      "MD 청크 1:\n",
      "# LangChain 가이드\n",
      "\n",
      "## 소개\n",
      "LangChain은 LLM 애플리케이션 개발 프레임워크입니다.\n",
      "\n",
      "## 주요 기능\n",
      "--------------------------------------------------\n",
      "MD 청크 2:\n",
      "## 주요 기능\n",
      "\n",
      "### 프롬프트 템플릿\n",
      "동적 프롬프트 생성을 지원합니다.\n",
      "\n",
      "### 체인\n",
      "여러 컴포넌트를 연결합니다.\n",
      "--------------------------------------------------\n",
      "MD 청크 3:\n",
      "## 시작하기\n",
      "```python\n",
      "from langchain import OpenAI\n",
      "llm = OpenAI()\n",
      "--------------------------------------------------\n",
      "MD 청크 4:\n",
      "```\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "\n",
    "markdown_text = \"\"\"\n",
    "# LangChain 가이드\n",
    "\n",
    "## 소개\n",
    "LangChain은 LLM 애플리케이션 개발 프레임워크입니다.\n",
    "\n",
    "## 주요 기능\n",
    "\n",
    "### 프롬프트 템플릿\n",
    "동적 프롬프트 생성을 지원합니다.\n",
    "\n",
    "### 체인\n",
    "여러 컴포넌트를 연결합니다.\n",
    "\n",
    "## 시작하기\n",
    "```python\n",
    "from langchain import OpenAI\n",
    "llm = OpenAI()\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# 마크다운 분할기\n",
    "md_splitter = MarkdownTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "md_chunks = md_splitter.split_text(markdown_text)\n",
    "\n",
    "print(f\"마크다운 청크 수: {len(md_chunks)}\\n\")\n",
    "for i, chunk in enumerate(md_chunks, 1):\n",
    "    print(f\"MD 청크 {i}:\\n{chunk}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 차원: 1536\n",
      "첫 번째 텍스트의 임베딩 (처음 10개 값): [-0.006174771580845118, -0.024400196969509125, -0.019658733159303665, -0.03282342851161957, 0.018368078395724297, 0.00598796596750617, -0.01618075557053089, 0.02467191405594349, 0.008402852341532707, 0.010433937422931194]\n",
      "\n",
      "텍스트 간 유사도:\n",
      "텍스트 1 <-> 텍스트 2: 0.8110\n",
      "텍스트 1 <-> 텍스트 3: 0.9208\n",
      "텍스트 2 <-> 텍스트 3: 0.7723\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "# 임베딩 모델 생성\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 텍스트 임베딩\n",
    "texts = [\n",
    "    \"LangChain은 AI 애플리케이션 프레임워크입니다.\",\n",
    "    \"파이썬은 프로그래밍 언어입니다.\",\n",
    "    \"LangChain을 사용하면 LLM 애플리케이션을 쉽게 만들 수 있습니다.\"\n",
    "]\n",
    "\n",
    "# 임베딩 생성\n",
    "embedded_texts = embeddings.embed_documents(texts)\n",
    "\n",
    "print(f\"임베딩 차원: {len(embedded_texts[0])}\")\n",
    "print(f\"첫 번째 텍스트의 임베딩 (처음 10개 값): {embedded_texts[0][:10]}\")\n",
    "\n",
    "# 유사도 계산 (코사인 유사도)\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "print(\"\\n텍스트 간 유사도:\")\n",
    "for i in range(len(texts)):\n",
    "    for j in range(i+1, len(texts)):\n",
    "        sim = cosine_similarity(embedded_texts[i], embedded_texts[j])\n",
    "        print(f\"텍스트 {i+1} <-> 텍스트 {j+1}: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 문서 로드, 분할, 임베딩 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 문서 길이: 226자\n",
      "분할된 청크 수: 4\n",
      "각 청크의 임베딩 차원: 1536\n",
      "\n",
      "청크 1: 인공지능(AI)은 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현한 컴퓨터 과학의 ...\n",
      "청크 2: 머신러닝은 AI의 한 분야로, 데이터로부터 패턴을 학습하여 예측이나 결정을 내리는 알고리즘...\n",
      "청크 3: 딥러닝은 머신러닝의 한 방법으로, 인공신경망을 여러 층으로 쌓아 복잡한 패턴을 학습합니다....\n",
      "청크 4: 자연어처리(NLP)는 컴퓨터가 인간의 언어를 이해하고 처리할 수 있도록 하는 AI 기술입니...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 샘플 문서 생성\n",
    "sample_content = \"\"\"\n",
    "인공지능(AI)은 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현한 컴퓨터 과학의 한 분야입니다.\n",
    "\n",
    "머신러닝은 AI의 한 분야로, 데이터로부터 패턴을 학습하여 예측이나 결정을 내리는 알고리즘을 연구합니다.\n",
    "\n",
    "딥러닝은 머신러닝의 한 방법으로, 인공신경망을 여러 층으로 쌓아 복잡한 패턴을 학습합니다.\n",
    "\n",
    "자연어처리(NLP)는 컴퓨터가 인간의 언어를 이해하고 처리할 수 있도록 하는 AI 기술입니다.\n",
    "\"\"\"\n",
    "\n",
    "with open(\"ai_intro.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sample_content)\n",
    "\n",
    "# 1. 문서 로드\n",
    "loader = TextLoader(\"ai_intro.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. 문서 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. 임베딩 생성\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embedded_docs = embeddings.embed_documents([doc.page_content for doc in splits])\n",
    "\n",
    "print(f\"원본 문서 길이: {len(documents[0].page_content)}자\")\n",
    "print(f\"분할된 청크 수: {len(splits)}\")\n",
    "print(f\"각 청크의 임베딩 차원: {len(embedded_docs[0])}\\n\")\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    print(f\"청크 {i+1}: {split.page_content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. FAISS 벡터 저장소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: '파이썬 프로그래밍'\n",
      "\n",
      "유사한 문서 (상위 3개):\n",
      "1. 파이썬은 배우기 쉬운 프로그래밍 언어입니다.\n",
      "2. 파이썬으로 AI 애플리케이션을 개발할 수 있습니다.\n",
      "3. LangChain은 LLM 애플리케이션 개발 프레임워크입니다.\n",
      "\n",
      "점수와 함께 검색:\n",
      "점수: 0.1417 - 파이썬은 배우기 쉬운 프로그래밍 언어입니다.\n",
      "점수: 0.1853 - 파이썬으로 AI 애플리케이션을 개발할 수 있습니다.\n",
      "점수: 0.4124 - LangChain은 LLM 애플리케이션 개발 프레임워크입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 샘플 문서들\n",
    "texts = [\n",
    "    \"파이썬은 배우기 쉬운 프로그래밍 언어입니다.\",\n",
    "    \"LangChain은 LLM 애플리케이션 개발 프레임워크입니다.\",\n",
    "    \"벡터 데이터베이스는 임베딩을 저장하고 검색합니다.\",\n",
    "    \"파이썬으로 AI 애플리케이션을 개발할 수 있습니다.\",\n",
    "    \"FAISS는 Facebook이 개발한 벡터 검색 라이브러리입니다.\"\n",
    "]\n",
    "\n",
    "# 벡터 저장소 생성\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "# 유사도 검색\n",
    "query = \"파이썬 프로그래밍\"\n",
    "results = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"쿼리: '{query}'\\n\")\n",
    "print(\"유사한 문서 (상위 3개):\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n",
    "\n",
    "# 점수와 함께 검색\n",
    "print(\"\\n점수와 함께 검색:\")\n",
    "results_with_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"점수: {score:.4f} - {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 벡터 저장소 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 저장소가 'faiss_index' 디렉토리에 저장되었습니다.\n",
      "벡터 저장소를 로드했습니다.\n",
      "\n",
      "쿼리: '벡터 검색'\n",
      "검색 결과:\n",
      "1. 벡터 데이터베이스는 임베딩을 저장하고 검색합니다.\n",
      "2. FAISS는 Facebook이 개발한 벡터 검색 라이브러리입니다.\n"
     ]
    }
   ],
   "source": [
    "# 벡터 저장소 저장\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "print(\"벡터 저장소가 'faiss_index' 디렉토리에 저장되었습니다.\")\n",
    "\n",
    "# 벡터 저장소 로드\n",
    "loaded_vectorstore = FAISS.load_local(\n",
    "    \"faiss_index\", \n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "print(\"벡터 저장소를 로드했습니다.\")\n",
    "\n",
    "# 로드된 저장소로 검색\n",
    "query = \"벡터 검색\"\n",
    "results = loaded_vectorstore.similarity_search(query, k=2)\n",
    "print(f\"\\n쿼리: '{query}'\")\n",
    "print(\"검색 결과:\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 메타데이터 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: '프로그래밍 언어'\n",
      "필터: category='programming'\n",
      "\n",
      "필터링된 결과:\n",
      "- 파이썬은 다양한 분야에서 사용됩니다.\n",
      "  메타데이터: {'category': 'programming', 'language': 'python'}\n",
      "- 자바스크립트는 웹 개발에 필수적입니다.\n",
      "  메타데이터: {'category': 'programming', 'language': 'javascript'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# 메타데이터가 있는 문서들\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"파이썬은 다양한 분야에서 사용됩니다.\",\n",
    "        metadata={\"category\": \"programming\", \"language\": \"python\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"자바스크립트는 웹 개발에 필수적입니다.\",\n",
    "        metadata={\"category\": \"programming\", \"language\": \"javascript\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"머신러닝은 데이터에서 패턴을 학습합니다.\",\n",
    "        metadata={\"category\": \"ai\", \"topic\": \"ml\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"딥러닝은 신경망을 사용합니다.\",\n",
    "        metadata={\"category\": \"ai\", \"topic\": \"dl\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 메타데이터와 함께 벡터 저장소 생성\n",
    "vectorstore_with_metadata = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# 메타데이터 필터링 검색\n",
    "query = \"프로그래밍 언어\"\n",
    "filter_dict = {\"category\": \"programming\"}\n",
    "\n",
    "# 필터 적용 검색 (FAISS는 직접적인 필터링을 지원하지 않으므로 전체 검색 후 필터링)\n",
    "all_results = vectorstore_with_metadata.similarity_search(query, k=10)\n",
    "filtered_results = [\n",
    "    doc for doc in all_results \n",
    "    if doc.metadata.get(\"category\") == \"programming\"\n",
    "]\n",
    "\n",
    "print(f\"쿼리: '{query}'\")\n",
    "print(f\"필터: category='programming'\\n\")\n",
    "print(\"필터링된 결과:\")\n",
    "for doc in filtered_results:\n",
    "    print(f\"- {doc.page_content}\")\n",
    "    print(f\"  메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 과제\n",
    "\n",
    "다음 과제들을 시도해보세요:\n",
    "\n",
    "1. 여러 파일을 로드하고 통합하여 벡터 저장소 만들기\n",
    "2. 다양한 청크 크기로 실험하고 검색 품질 비교\n",
    "3. 커스텀 메타데이터를 추가하여 고급 필터링 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 실습 코드를 작성하세요\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
